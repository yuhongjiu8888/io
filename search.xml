<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[C/C++编程]]></title>
    <url>%2F2020%2F03%2F10%2FC%2B%2B%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E7%9A%84%E5%A3%B0%E6%98%8E%E5%92%8C%E5%AE%9A%E4%B9%89%2F</url>
    <content type="text"><![CDATA[C++全局变量的声明和定义声明与定义函数或变量在声明时，并没有给它实际的物理内存空间，它有时候可保证你的程序编译通过； 函数或变量在定义时，它就在内存中有了实际的物理空间。 如果你在编译单元中引用的外部变量没有在整个工程中任何一个地方定义的话，那么即使它在编译时可以通过，在连接时也会报错，因为程序在内存中找不到这个变量。 函数或变量可以声明多次，但定义只能有一次。 extern作用作用一：当它与”C”一起连用时，如extern “C” void fun(int a, int b);，则编译器在编译fun这个函数名时按C的规则去翻译相应的函数名而不是C++的。作用二：当它不与”C”在一起修饰变量或函数时，如在头文件中，extern int g_nNum;，它的作用就是声明函数或变量的作用范围的关键字，其声明的函数和变量可以在本编译单元或其他编译单元中使用。 即B编译单元要引用A编译单元中定义的全局变量或函数时，B编译单元只要包含A编译单元的头文件即可，在编译阶段，B编译单元虽然找不到该函数或变量，但它不会报错，它会在链接时从A编译单元生成的目标代码中找到此函数。 extern声明全局变量的时候，表明在一个文件地方声明定义后，其他文件中需要使用的时候需要声明在变量前声明为extern.例如在A.cpp中，声明定义变量g_keyApi; 123//A.cppfit::KeyApi::KaClass g_KeyApi = NULL;g_KeyApi = new KaClass(); 在B.cpp中需要使用g_KeyApi时，可以在文件头部这样声明： 123//B.cppextern fit::KeyApi::KaClass g_KeyApi;g_KeyApi-&gt;signCheck();//验签 这样可以让B.cpp在编译的时候通过，连接的时候再去找obj。 静态全局变量(static)注意使用static修饰变量，就不能使用extern来修饰，即static和extern不可同时出现。 static修饰的全局变量的声明与定义同时进行，即当你在头文件中使用static声明了全局变量，同时它也被定义了。 static修饰的全局变量的作用域只能是本身的编译单元。在其他编译单元使用它时，只是简单的把其值复制给了其他编译单元，其他编译单元会另外开个内存保存它，在其他编译单元对它的修改并不影响本身在定义时的值。即在其他编译单元A使用它时，它所在的物理地址，和其他编译单元B使用它时，它所在的物理地址不一样，A和B对它所做的修改都不能传递给对方。 多个地方引用静态全局变量所在的头文件，不会出现重定义错误，因为在每个编译单元都对它开辟了额外的空间进行存储。 注：一般定义static 全局变量时，都把它放在.cpp文件中而不是.h文件中，这样就不会给其他编译单元造成不必要的信息污染。 全局常量(const)const单独使用时，其特性与static一样（每个编译单元中地址都不一样，不过因为是常量，也不能修改，所以就没有多大关系）。 const与extern一起使用时，其特性与extern一样。 12extern const char g_szBuffer[]; //写入 .h中const char g_szBuffer[] = "123456"; // 写入.cpp中]]></content>
      <tags>
        <tag>技术,编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++编程]]></title>
    <url>%2F2020%2F03%2F10%2F%E6%87%92%E6%B1%89%E6%A8%A1%E5%BC%8F%E4%B8%8E%E9%A5%BF%E6%B1%89%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[懒汉模式与饿汉模式单例懒汉模式：需要使用的时候在进行实例化，加载速度快，调用慢。非线程安全 单例饿汉模式：在声明的时候立即初始化实例化，加载速度慢，调用速度快。线程安全]]></content>
      <tags>
        <tag>技术,编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fabric源码分析]]></title>
    <url>%2F2020%2F03%2F10%2Ffabric%2F</url>
    <content type="text"><![CDATA[Fabric简介​ Hyperledger Fabric 是一个模块化架构的分布式账本平台，提供高度的机密性，弹性，灵活性和可扩展性。它旨在支持不同组件的可插拔实现，并且可以容纳生态系统中存在的高度复杂应用。 超级账本项目为透明、公开、去中心化的企业级分布式账本技术提供开源参考实现。 区块链是什么1.分布式账本（A Distributed Ledger） 区块链网络的核心是一个分布式账本，用于记录在网络上发生的所有交易。区块链账本通常被描述为去中心化的，因为它被复制到许多网络参与者中，每个参与者都在协作维护。我们将看到，分权和协作是反映企业在现实世界中交换产品和服务方式的强大属性。 除了去中心化和协作之外，记录在区块链中的信息只能追加，使用加密技术可保证一旦交易添加在账本中，便无法对其进行修改。这种无法篡改的特性使得判断信息的来源变得很简单，因为参与者可以肯定信息在事后没有被改变。这就是区块链有时被描述为证明体系的原因。 2.智能合约（Smart Contracts） 为了支持信息一致性更新 —— 启用一整作用于账本的功能（交易，查询等） —— 区块链网络使用智能合约来提供对账本访问控制。 智能合约不仅是简单的封装信息在整个网络中同步，它们也可以被写入以允许参与者的一些交易能自动执行。例如，可以写一份智能合约，通过物品何时到达来决定传输费用。双方一旦同意该条款并写入账本中，当商品到达时，相应的资金将会自动被转入。 3.共识（Consensus） 通过网络保持分类账交易同步的过程 — 确保账本只有在交易获得相应的参与者批准时才更新，并且当账本更新时，它们以包含相同的顺序区块来更新账本 — 这个过程就称为共识。 我们将在后面学习更多关于账本、智能合约和共识的知识。就目前而言，将区块链视为共享的、复制的交易系统就足够了，该交易系统通过智能合约进行更新，并通过称为共识的协作过程保持一致同步。 Fabric的特点 Hyperledger Fabric 是 Hyperledger 中的区块链项目之一。像其他区块链技术一样，它具有账本，使用智能合约，并且系统是参与者管理其交易的。 Hyperledger Fabric从其他一些区块链系统中脱颖而出的地方在于它是私密的并且是权限化的。相对于允许未知身份参与网络的开放式权限系统（需要工作证明等协议来验证交易和保护网络）。Hyperledger Fabric 网络的成员通过注册可信成员服务提供商（Membership Service Provider 简称 MSP）来保证系统的私密性。 Hyperledger Fabric 还提供多种可热插拔选项。账本数据可以以多种格式来存储，共识机制可以随时切换开关，并支持多种的MSP。 Hyperledger Fabric 还提供了创建频道（channels）的能力，允许一组参与者创建单独的交易账本。对网络参与者中有潜在的竞争对手的情况下，这是一个特别重要的选择 — 例如，他们向某些参与者提供的特殊价格 — 每位参与者都知道。如果两个参与者都在一个频道，那么这些参与者（没有其他人）就拥有该频道的账本副本。 共享账本（Shared Ledger） Hyperledger Fabric 的账本系统有两个组件：世界状态（world state）和事务日志（transaction log）。每个参与者都将分类帐的副本分配给所属的每个 Hyperledger Fabric 网络。Hyperledger Fabric 中的网络参与者都有一本账本副本。 世界状态组件描述了在特定时间点下账本的状态。这是相当于账本的数据库。交易日志组件记录了构成世界状态的所有交易;由此得出，账本是世界状态数据库和交易日志历史记录的组合。 账本对世界状态有可替换的数据存储。默认情况下，这是一个 LevelDB 键值存储数据库。事务日志不需要是可插拔的。它只记录区块链网络中使用的账本数据库的前后值。 智能合约（Smart Contracts） Hyperledger Fabric 的智能合约是用 chaincode 实现的，并且被区块链外部应用程序所调用，以此来与账本交互。在大多数情况下，chaincode 仅与账本的数据库组件（世界状态）（例如查询）交互，而不与交易日志交互。 私密性（Privacy） 根据网络的需求，企业对企业（B2B）网络的参与者可能对他们共享多少信息非常敏感。对于其他区块链网络而言，隐私不会成为首要问题。 相遇对其他的区块链网络，隐私（使用频道方法）对于 Hyperledger Fabric 是非常关键的要求。 共识（Consensus） 交易必须按照发生的顺序写入账本中，网络中不同的参与者皆是如此。要做到这点，必须建立交易顺序，并且必须实施一种方法，用于拒绝错误（或恶意）插入账本的不良交易。 这是一个老生常谈的计算机科学领域，有很多方法可以实现共识算法，每个方法都有不同的利弊。例如，PBFT（Practical Byzantine Fault Tolerance）可以提供文件副本相互通信的机制，以保持每个副本的一致性，即使在发生损坏的情况下。或者，在比特币中，通过计算加密问题（也被称为挖矿）来实现共识，谁先算出来该区块就算谁的。 Hyperledger Fabric 共识机制，其中目前包括 SOLO，Kafka ，会很快将了解到 SBFT（简化的拜占庭容错）。 Fabric应用场景 Fabric由于其联盟链的特性，可以面向企业内部或多个企业之间的商业区块链应用场景，将区块链的维护节点和可见性限制在联盟内部，并用智能合约（链码）重点解决联盟成员间的信任或信息不对等问题，以提高经济活动效率。Fabric主要应用的场景如下：➤金融服务：Fabric可以有效降低交易成本和管控风险、减少跨组织的交易风险，其在金融领域的应用受到了不少银行和金融交易机构的主要推动。➤征信和资产权属管理：Fabric可以促进数据的交易和流动；提供安全可靠的支持。特别是资产权属的管理，利用区块链平台建立的多方信任机制可以有效降低资产交易成本和违约风险。➤国际自动化贸易和供应链管理：Fabric可以简化管理流程中繁琐的手续。利用智能合约，贸易中销售和法律合同可以数字化、可以实现货物监控和实时支付，大大降低了公司的运营成本。 Fabric参考手册peers对等节点 ledger账本 Fabric的基本框架 Fabric的基本逻辑架构 Fabric共识模式fabric共识模式采用的 Endorse+Kafka+Commit 的模式，这里我们简称EKC共识。此共识包含以下几个步骤： 1.请求背书：客户端用自己的私钥对交易进行签名后，按照指定格式将交易和签名信息进行打包，然后将打包后的数据发给背书节点请求背书。 2.验证背书：背书节点收到背书请求后，验证交易的签名是否正确并调用智能合约验证交易内容是否合法。验证通过的话，背书节点用自己的私钥对背书结果进行签名并按照指定格式打包，然后将打包后的数据发给客户端。 3.提交交易：客户端收到背书结果后，验证背书结果的签名是否正确。验证通过后，对交易请求和背书结果签名并打包。然后，把打包后的数据发送给orderer节点提交交易。 4.排序广播：orderer节点收到交易后，验证数据的客户端签名[bJ1] 是否正确。验证通过后，将交易发给kafka集群对应的topic。由于orderer中的对于每个通道都在kafka上监听对应的消息，因此，kafka将消息存放到对应topic上之后，会将消息广播给通道上的所有orderer。因为各个orderer的消息都是由kafka按照相同顺序发送的，因此，这个过程也实现了消息的排序。 5.打包出块：orderer节点接收到从kafka推送的消息（kafka节点见同步消息不需要验证），当满足出块策略[bJ2] ：缓存交易个数达到区块最大交易数或者时间达到出快时间，则将交易进行打包、对数据签名，然后出块，并将区块分发给peer节点。 6.验证记账：peer节点接收到区块后，验证交易是否有效即验证区块的交易是否满足背书策略以及区块中交易的读写集版本是否正确[bJ3] 。验证通过的话，执行此交易的内容更改状态数据库。验证失败的话，对此条交易不做任何处理。当区块中的交易全部处理完成后，将区块记录在本地数据库。 Fabric源码解析一、整体结构​ Hyperledger Fabric 在 1.0 中，架构已经解耦为三部分： ​ peer：主要起到 peer 作用，包括 endorser、committer 两种角色； ​ ca：即原先的 membersrvc，独立成一个新的项目。 ​ order：起到 order 作用。 ​ 其中，peer 和 order 代码暂时都在 fabric 项目中，未来可能进一步拆分。 启动过程：orderer0,peer0,peer1,peer2,peer3,cli六个容器服务，首先在容器启动的时候order程序,然后在启动peer节点容器，相当于启动peer程序，最后启动cli容器。 通过docker相关启动脚本，orderer容器先起，各个peer之间其实可以没有先后顺序但是都必须后与orderer容器，最后是cli容器。这说明，orderer服务必须先于peer服务，peer node start命令必须先于peer channel或peer chaincode命令。 二、源代码说明：以下讲解代码基于fabric 1.0版本（github地址） 实现fabric功能的核心代码，包括： ​ bccsp包：实现对加解密算法和机制的支持。 ​ common包：一些通用的模块； ​ core包：大部分核心实现代码都在本包下。其他包的代码封装上层接口，最终调用本包内代码； ​ events包：支持event框架； ​ examples包：包括一些示例的chaincode代码； ​ gossip包：实现gossip协议； ​ msp包：Member Service Provider 包； ​ order包：order服务相关的入口和框架代码； ​ peer包：peer的入口和框架代码； ​ protos包：包括各种协议和消息的protobuf定义文件和生成的go文件。 ​ 一些辅助代码包，包括： ​ bddtests包: 测试包，含大量bdd测试用例； ​ gotools包：golang开发相关工具安装； ​ vendor包： 管理依赖； ​ 安装部署包括： ​ busybox包：busybox环境，精简的Linux; ​ devenv包：配置开发环境； ​ images包：镜像生成模板等； ​ scripts包：各种安装配置脚本； 三、核心过程​ 总结一下核心核心的过程。 3.1 Chaincode启动过程​ Hyperledger Fabric中，Chaincode默认运行在Docker容器中。Peer通过调用Docker API来创建和启动Chaincode容器。Chaincode容器启动后跟Peer之间创建gRPC连接，双方通过发送ChaincodeMessage来进行交互通信。Chaincode容器利用core.chaincode.shim包提供的接口来向Peer发送请求。 ​ 典型结构 ​ 下面给出了链码的典型结构，用户只需要关注到 Init() 和 Invoke() 函数的实现上，在其中利用 ​ shim.ChaincodeStubInterface 结构，实现跟账本的交互逻辑。 ​ 123456789101112131415161718192021222324package main import ( "errors" "fmt" "github.com/hyperledger/fabric/core/chaincode/shim" )type DemoChaincode struct &#123; &#125; func (t *DemoChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response &#123; // more logics using stub here return stub.Success(nil) &#125;func (t *DemoChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response&#123; // more logics using stub here return stub.Success(nil) &#125;func main() &#123; err := shim.Start(new(DemoChaincode)) if err != nil &#123; fmt.Printf("Error starting DemoChaincode: %s", err) &#125; &#125; ​ Chaincode首先是一个普通的goland程序，其main方法中调用了shim层的Start()方法。启动过程如下图所示： ​ 图 Chaincode* 启动过程 首先会进行初始化。包括读取默认配置，创建到 Peer 的gRPC 连接，主要包括 NewChaincodeSupportClient(cc *grpc.ClientConn) 和 chaincodeSupportClient.Register(ctx context.Context, opts …grpc.CallOption) 两个方法。 初始化完成后，创建有限状态机结构（FSM，github.com/looplab/fsm）。FSM 会根据收到的 消息和当前状态来触发状态转移，并执行提前设置的操作。 Peer 侧也利用了类似的 FSM 结构来管理消息响应。 之后，利用创建好的 gRPC 连接开始向 Peer 发送第一个 gRPC 消息： ChaincodeMessage_REGISTER，将自身注册到 Peer 上。注册成功后开始消息处理循环， 等待接收来自 Peer 的消息以及自身的状态迁移（nextState）消息。 后续过程中，Chaincode 和 Peer 利用 FSM 完成一系列对消息的响应运作，如下所示。 ​ Peer 收到来自链码容器的 ChaincodeMessage_REGISTER 消息，将其注册到本地的一 个 Handler 结构，返回 ChaincodeMessage_REGISTERED 消息发给链码容器。之后更 新状态为 established ，并发送 ChaincodeMessage_READY 消息给链码侧，更新状态 为 ready。 链码侧收到 ChaincodeMessage_REGISTERED 消息后，不进行任何操作，注册成功。 更新状态为 established。收到 ChaincodeMessage_READY 消息后更新状态为 ready。 Peer 侧发出 ChaincodeMessage_INIT 消息给链码容器，准备触发链码侧初始化操作。 链码容器收到 ChaincodeMessage_INIT 消息，通过 Handler.handleInit() 方法进行进行 初始化。主要包括初始化所需的 ChaincodeStub 结构，以及调用链码代码中的 Init() 方 法。初始化成功后，返回 ChaincodeMessage_COMPLETED 消息给 Peer。此时，链码 容器进入可被调用（Invoke）状态。 链码被调用时，Peer 发出 ChaincodeMessage_TRANSACTION 消息给链码。 链码收到 ChaincodeMessage_TRANSACTION 消息，会调用 Invoke() 方法，根据 Invoke 方法中用户实现的逻辑，可以发出包括 ChaincodeMessage_GET_HISTORY_FOR_KEY、ChaincodeMessage_GET_QUERY_RESULT、ChaincodeMessage_GET_STATE、ChaincodeMessage_GET_STATE_BY_RANGE、 ChaincodeMessage_QUERY_STATE_CLOSE、ChaincodeMessage_QUERY_STATE_NEXT、 ChaincodeMessage_INVOKE_CHAINCODE 等消息给 Peer 侧。Peer 侧收到这些消 息，进行相应的处理，并回复 ChaincodeMessage_RESPONSE 消息。最后，链码侧会 回复调用完成的消息 ChaincodeMessage_COMPLETE 给 Peer 侧。 在上述过程中，Peer 和链码侧还会定期的发送 ChaincodeMessage_KEEPALIVE 消息给 对方，以确保彼此在线。 3.2 Peer节点启动3.2.1 Peer背书提案过程​ 客户端将交易预提案（Transaction Proposal)通过 gRPC 发送给支持 Endorser 角色的 Peer 进行背书。 这些交易提案可能包括链码的安装、实例化、升级、调用、查询；以及 Peer 节点加入和列出 通道操作。 Peer 接收到请求后，会调用 core/endorser/endorser.go 中 Endorser 结构体 的 ProcessProposal(ctx context.Context, signedProp *pb.SignedProposal) (*pb.ProposalResponse, error) 方法，进行具体的背书处理。 背书过程主要完成如下操作： 检查提案消息的合法性，以及相关的权限； 模拟执行提案：启动链码容器，对世界状态的最新版本进行临时快照，基于它执行链 码，将结果记录在读写集中； 对提案内容和读写集合进行签名，并返回提案响应消息。 123456789101112131415func (e *Endorser) ProcessProposal(ctx context.Context, signedProp *pb.SignedProposal) (*pb.ProposalResponse, error) &#123; //检查交易的合法性 prop, hdr, hdrExt, err := validation.ValidateProposalMessage(signedProp) //该方法主要是Peer节点模拟提案过程，但是不会写入到区块中，当Peer节点模拟完一项提案，将模拟结果保存至读写集。 cd, res, simulationResult, ccevent, err := e.simulateProposal(ctx, chainID, txid, signedProp, prop, hdrExt.ChaincodeId, txsim) if chainID == "" &#123; pResp = &amp;pb.ProposalResponse&#123; Response: res &#125;else&#123; pResp, err = e.endorseProposal(ctx, chainID, txid, signedProp, prop, res, simulationResult, ccevent, hdrExt.PayloadVisibility, hdrExt.ChaincodeId, txsim, cd) &#125; return pResp, nil&#125; 主要过程如下图所示。 ​ Endorser ProcessProposal 过程 检查提案合法性； 调用 ValidateProposalMessage() 方法对签名的提案进行格式检查，主要包括： Channel 头部格式：是否合法头部类型，由 validateChannelHeader() 完成； 签名头格式：是否包括了 nonce 和creators 数据，由validateSignatureHeader() 完成； 签名域：creator 证书 MSP 检查是否合法，签名是否正确，由checkSignatureFromCreator() 完成。 如果是系统链码调用（SCC），检查是否是允许从外部调用的三种 SCC 之一：cscc、lscc、qscc 或 rscc； 如果 chainID 不为空，获取对应 chain 的账本结构，并检查 TxID 唯一性，确保同一交易未曾提交到账本结构中； 对于用户链码调用，需要检查 ACL：资源为 PROPOSE ，默认策略是签名提案者在通道上拥有写权限（ CHANNELWRITERS ）。 模拟执行提案 如果 chainID 不为空，获取对应账本的交易模拟器（TxSimulator）和历史查询器（HistoryQueryExecutor），这两个结构将在后续执行链码时被使用。 如果 chainID 不为空，调用 simulateProposal() 方法获取模拟执行的结果，检查返回的响应 response 的状态，若不小于错误 500 则创建并返回一个失败的ProposalResponse。 对提案内容和读写集合进行签名 chainID 非空情况下，调用 endorseProposal() 方法利用 ESCC，对之前得到的模拟执行的结果进行背书。返回 ProposalResponse，检查 simulateProposal 返回的response 的状态，若不小于错误阈值 400（被背书节点反对），返回ProposalResponse 及链码错误 chaincodeError（endorseProposal 里有检查链码执行结果的状态，而 simulateProposal 没有检查）。 将 response.Payload 赋给 ProposalResponse.Response.Payload（因为simulateProposal 返回的 response 里面包含链码调用的结果）。 返回响应消息 ProposalResponse。 simulateProposal 方法 ​ simulateProposal 方法会通过执行链码逻辑来获取对状态的修改结果，并存放到读写集合 中，主要过程如下： 从提案结构的载荷中提取 ChaincodeInvocationSpec 结构，其中包含了所调用链码（包括系统链码和用户链码）的路径、名称和版本，以及调用时传入的参数列表； 检查 ESCC 和 VSCC（尚未实现）； 对用户链码，检查提案中的实例化策略跟账本上记录的该链码的实例化策略（安装链码时指定）是否一致。防止有人修改权限在其它通道非法实例化。 调用 callChaincode() 方法执行 Proposal，返回 Response 和 ChaincodeEvent。 调用 core.endorser 包中 SupportImpl.Execute() 方法，该方法主要调用core.chaincode 包中的 ExecuteChaincode() 方法，进一步调用包内的 Execute()方法。调用过程中会把交易模拟器和历史查询器通过上下文结构体传入后续子方法。 Execute() 方法会调用 ChaincodeSupport.Launch() 方法创建并启动链码容器。启动成功后创建链码 gRPC 消息，通过 ChaincodeSupport.Execute() 方法发送消息给CC 容器，执行相关的合约，并返回执行响应（ChaincodeMessage 结构）。此过程 中会将读写集记录到交易模拟器结构体中。 对于非空 chainID（大部分跟账本相关的操作），执行 GetTxSimulationResults() 拿到执行结果 TxSimulationResults 结构，从中可以解析出读写集数据。 最终返回链码标准数据结构 ChaincodeDefinition、响应消息 ChaincodeMessage、交易读写集 PubSimulationResults、链码事件 ChaincodeEvent。 endorseProposal 方法 主要过程如下： 获取被调用的链码指定的背书链码的名字。 通过 callChaincode() 实现对背书链码的调用，返回响应 response（对 ESCC 的调用同样也会产生 simulation results，但 ESCC 不能背书自己产生的simulation results，需要背书最初被调用的链码产生的 simulation results）。 检查 response.Status，是否大于等于 400（错误阈值），若是则把 response 赋给proposalResponse.Response 并返回 proposalResponse。 将 response.Payload解码后（ProposalResponse类型）返回。 callChaincode 方法 主要过程如下： 判断交易模拟器，不为空则把它加入到Context的K-V存储中。 判断被call的cc是不是系统链码，创建CCContext（包含通道名、链码名、版本号、交易ID、是否 SCC、签名 Prop、Prop） 调用 core/chaincode/chaincodeexec.go 下的 ExecuteChaincode()，返回响应 response和 事件ccevent。 返回 response和ccevent。 3.3排序服务核心原理和工作过程​ 排序服务在超级账本 Fabric 网络中起到十分核心的作用。所有交易在发送给 Committer 进行 验证接受之前，需要先经过排序服务进行全局排序。 在目前架构中，排序服务的功能被抽取出来，作为单独的 fabric-orderer 模块来实现，代码主 要在 fabric/orderer 目录下。 下面以 Kafka 作为共识插件为例，讲解 Orderer 节点的核心过程。 3.3.1工作原理Orderer 节点（Ordering Service Node，OSN）在网络中起到代理作用，多个 Orderer 节点 会连接到 Kafka 集群，利用 Kafka 的共识功能，完成对网络中交易的排序和打包成区块的工 作。 Fabric 网络提供了多通道特性，为了支持这一特性，同时保障每个 Orderer 节点上数据的一 致性，排序服务进行了一些特殊设计。 对于每个通道，Orderer 将其映射到 Kafka 集群中的一个 topic （topic 名称与 channelID 相 同）上。由于 Orderer 目前并没有使用 Kafka Topic 的多分区负载均衡特性，默认每个 topic 只创建了一个分区（0 号分区）。 此外，Orderer 还在本地维护了针对每个通道的账本（区块链）结构，其中每个区块包括了一 组排序后的交易消息，并且被分割为独立区块。 核心过程如下所示： ​ Orderer 节点核心过程 客户端通过 gRPC 连接发送交易信息到 Orderer 节点的 Broadcast() 接口。 Orderer 节点收到请求后，提取消息进行解析、检查，通过检查后封装为 Kafka 消息，通过 Produce 接口发送到 Kakfa 集群对应的 topic 分区中。 当前收到消息数达到 BatchSize.MaxMessageCount 或消息尺寸过大，或超时时间达到 BatchTimeout，则发送分块消息 TTC-X 到 Kafka。 Kafka 集群维护多个 topic 分区。Kakfa 通过共识算法来确保写入到分区后的消息的一致性。即一旦写入分区，任何 Orderer 节点看到的都是相同的消息队列。 Orderer 节点在启动后，还默认对本地账本对应的 Kafka 分区数据进行监听，不断从Kafka 拉取（Consume）新的交易消息，并对消息进行处理。满足一定策略情况下（收到 TTX-C 或配置消息）还会将消息打包为区块。 3.4Orderer 节点启动过程Orderer 节点启动通过 orderer 包下的 main() 方法实现，会进一步调用到orderer/common/server包中的 Main() 方法。 核心代码如下所示。 12345678910111213141516// Main is the entry point of orderer processfunc Main() &#123; fullCmd := kingpin.MustParse(app.Parse(os.Args[1:])) // "version" command if fullCmd == version.FullCommand() &#123; fmt.Println(metadata.GetVersionInfo()) return &#125; conf := config.Load() initializeLoggingLevel(conf) initializeLocalMsp(conf) Start(fullCmd, conf)&#125; 包括配置初始化过程和核心启动过程两个部分： config.Load()：从本地配置文件和环境变量中读取配置信息，构建配置树结构。 initializeLoggingLevel(conf)：配置日志级别。 initializeLocalMsp(conf)：配置 MSP 结构。 Start()：完成启动后的核心工作。 核心启动过程都在 orderer/common/server 包中的 Start() 方法，如下图所示。 ​ Orderer 启动的整体过程 Start() 方法会初始化 gRPC 服务需要的结构，然后启动服务。 核心代码如下所示。 123456789101112131415161718192021func Start(cmd string, conf *config.TopLevel) &#123; logger.Debugf("Start()") signer := localmsp.NewSigner() manager := initializeMultichannelRegistrar(conf, signer) server := NewServer(manager, signer, &amp;conf.Debug) switch cmd &#123; case start.FullCommand(): // "start" command logger.Infof("Starting %s", metadata.GetVersionInfo()) initializeProfilingService(conf) grpcServer := initializeGrpcServer(conf) ab.RegisterAtomicBroadcastServer(grpcServer.Server(), server) logger.Info("Beginning to serve requests") grpcServer.Start() case benchmark.FullCommand(): // "benchmark" command logger.Info("Starting orderer in benchmark mode") benchmarkServer := performance.GetBenchmarkServer() benchmarkServer.RegisterService(server) benchmarkServer.Start() &#125;&#125; 包括两大部分： gRPC 服务结构初始化； gRPC 服务启动。 3.4.1 gRPC 服务结构初始化包括创建新的 MSP 签名结构，初始化 Registrar 结构来管理各个账本结构，启动共识过程，以及创建 gRPC 服务端结构。 核心步骤包括： 12signer := localmsp.NewSigner() // 初始化签名结构manager := initializeMultichannelRegistrar(conf, signer, tlsCallback) // 初始化账本管理器（Registrar）结构 其中， initializeMultichannelRegistrar(conf, signer) 方法最为关键，核心代码如下： 12345678910111213141516171819func initializeMultichannelRegistrar(conf *config.TopLevel, signer crypto.LocalSigner,callbacks ...func(bundle *channelconfig.Bundle)) *multichannel.Registrar &#123; // 创建操作账本的工厂结构 lf, _ := createLedgerFactory(conf) // 如果是首次启动情况，默认先创建系统通道的本地账本结构 if len(lf.ChainIDs()) == 0 &#123; logger.Debugf("There is no chain, hence we must be in bootstrapping") initializeBootstrapChannel(conf, lf) &#125;else&#123; logger.Info("Not bootstrapping because of existing chains") &#125; //初始化共识插件，共识插件负责跟后台的队列打交道 consenters := make(map[string]consensus.Consenter) consenters["solo"] = solo.New() consenters["kafka"] = kafka.New(conf.Kafka.TLS, conf.Kafka.Retry, conf.Kafka.Version, conf.Kafka.Verbose) // 创建各个账本的管理器（Registrar）结构，并启动共识过程 return multichannel.NewRegistrar(lf, consenters, signer, callbacks...)&#125; 利用传入的配置信息和签名信息完成如下步骤： 创建账本操作的工厂结构； 如果是新启动情况，利用给定的系统初始区块文件初始化系统通道的相关结构； 完成共识插件（包括 solo 和 kafka 两种）的初始化； multichannel.NewRegistrar(lf, consenters, signer) 方法会扫描本地账本数据（此时至少已存在系统通道），创建 Registrar 结构，并为每个账本都启动共识（如 Kafka 排序）过程。 说明：Registrar 结构（位于 orderer.common.multichannel 包）是 Orderer 组件中最核心的结构，管理了 Orderer 中所有的账本、共识插件等数据结构。 3.4.2 创建 Registrar 结构并启动共识过程 NewRegistrar(lf, consenters, signer) 方法位于 orderer.common.multichannel 包，负责初始化链支持、消息处理器等重要数据结构，并为各个账本启动共识过程。 核心代码如下： 1234567891011121314existingChains := ledgerFactory.ChainIDs()for _, chainID := range existingChains &#123; // 启动本地所有的账本结构的共识过程 if _, ok := ledgerResources.ConsortiumsConfig(); ok &#123; // 如果是系统账本（默认在首次启动时会自动创建） chain := newChainSupport(r, ledgerResources, consenters, signer) chain.Processor = msgprocessor.NewSystemChannel(chain, r.templator, msgprocessor.CreateSystemChannelFilters(r, chain)) r.chains[chainID] = chain r.systemChannelID = chainID r.systemChannel = chain defer chain.start() // 启动共识过程 else // 如果是应用账本 chain := newChainSupport(r, ledgerResources, consenters, signer) r.chains[chainID] = chain chain.start() // 启动共识过程 &#125; chain.start() 方法负责启动共识过程。以 Kafka 共识插件为例，最终以协程方式调用到 orderer.consensus.kafka 包中的 startThread() 方法，将在后台持续运行。 123func (chain *chainImpl) Start() &#123; go startThread(chain)&#125; startThread() 方法将为指定的账本结构配置共识服务，并将其启动，核心代码包括： 12345678910111213// 创建 Producer 结构chain.producer, err = setupProducerForChannel(chain.consenter.retryOptions(), chain.haltChan, chain.SharedConfig().KafkaBrokers(), chain.consenter.brokerConfig(), chain.channel)// 发送 CONNECT 消息给 Kafka，如果失败，则退出sendConnectMessage(chain.consenter.retryOptions(), chain.haltChan, chain.producer, chain.channel)// 创建处理对应 Kafka topic 的 Consumer 结构chain.parentConsumer, err = setupParentConsumerForChannel(chain.consenter.retryOptions(), chain.haltChan, chain.SharedConfig().KafkaBrokers(), chain.consenter.brokerConfig(), chain.channel)// 配置从指定 partition 读取消息的 PartitionConsumer 结构chain.channelConsumer, err = setupChannelConsumerForChannel(chain.consenter.retryOptions(), chain.haltChan, chain.parentConsumer, chain.channel, chain.lastOffsetPersisted+1)// 从该链对应的 Kafka 分区不断读取消息，并进行处理过程chain.processMessagesToBlocks() 主要包括如下步骤： 创建到 Kafka 集群的 Producer 结构并发送 CONNECT 消息； 为对应的 topic 创建 Consumer 结构，并配置从指定分区读取消息的 PartitionConsumer结构； 对链对应的 Kafka 分区中消息的进行循环处理。 3.4.2 gRPC服务启动 初始化 gRPC 服务结构，完成绑定并启动监听。 123456789// 初始化 gRPC 服务端结构server := NewServer(manager, signer, &amp;conf.Debug)// 创建 gRPC 服务连接grpcServer := initializeGrpcServer(conf)// 绑定 gRPC 服务并启动ab.RegisterAtomicBroadcastServer(grpcServer.Server(), server)grpcServer.Start() 其中， NewServer(manager, signer, &amp;conf.Debug) 方法（位于 orderer.common.server 包）最为核心，将 gRPC 相关的服务结构进行初始化，并绑定到 gRPC 请求上。分别响应 Deliver() 和 Broadcast() 两个 gRPC 调用。 123456789// NewServer creates an ab.AtomicBroadcastServer based on the broadcast target and ledger Readerfunc NewServer(r *multichannel.Registrar, _ crypto.LocalSigner, debug *localconfig.Debug) ab.AtomicBroadcastServer &#123; s := &amp;server&#123; dh: deliver.NewHandlerImpl(deliverSupport&#123;Registrar: r&#125;), bh: broadcast.NewHandlerImpl(broadcastSupport&#123;Registrar: r&#125;), debug: debug, &#125; return s&#125; 3.5 Orderer 节点对排序后消息的处理过程经过排序后的消息，可以认为在网络中已经达成了基本的共识。Orderer 会获取这些消息，进行对应处理（包括打包为区块，更新本地账本结构等）。 以 Kafka 模式为例，Orderer 节点启动后，会调用 orderer/consensus/kafka 模块中 chainImpl 结构体的 processMessagesToBlocks() ([]uint64, error) 方法，持续获取 Kafka对应分区中的消息。 主要过程 chainImpl 结构体的 processMessagesToBlocks() 方法不断从分区中 Consume 消息并进行处理，同时定时发送 TimeToCut 消息。 处理消息类型包括 Connect 消息（Producer 启动后发出）、TimeToCut 消息和 Regular 消息（Fabric 消息）。分别调用对应方法进行处理，主要流程如下： 1234567891011121314151617181920212223// orderer/consensus/kafka/chain.gofor &#123; select &#123; case &lt;-chain.haltChan: // 链故障了，退出 case kafkaErr := &lt;-chain.channelConsumer.Errors(): //获取 Kakfa 消息发生错误 select &#123; case &lt;-chain.errorChan: // 连接关闭，不进行任何操作 default: //其它错误，OutofRange，关闭 errorChan；否则进行超时重连 &#125; select &#123; case &lt;-chain.errorChan: // 连接仍然关闭，尝试后台进行重连 &#125; case &lt;-topicPartitionSubscriptionResumed: // 继续 case &lt;-deliverSessionTimedOut: //访问超时，尝试后台进行重连 case in, ok := &lt;-chain.channelConsumer.Messages(): // 核心过程：成功读取到 Kafka消息，进行处理 switch msg.Type.(type) &#123; case *ab.KafkaMessage_Connect: // Kafka 连接消息，忽略 case *ab.KafkaMessage_TimeToCut: // TTC，打包现有的一批消息为区块 case *ab.KafkaMessage_Regular: // 核心处理：Fabric 相关消息，包括配置更新、应用通道交易等 chain.processRegular(msg.GetRegular(), in.Offset) case &lt;-chain.timer: //定期发出 TimeToCut 消息到 Kafka &#125; &#125; 3.5.1 Fabric 相关消息的处理对于 Fabric 相关消息（包括交易消息和配置消息），具体会调用 chainImpl 结构体的 processRegular(regularMessage ab.KafkaMessageRegular, receivedOffset int64) error 方法进行处理。 该方法的核心代码如下： 123456789101112// orderer/consensus/kafka/chain.gofunc (chain *chainImpl) processRegular(regularMessage *ab.KafkaMessageRegular, receivedOffset int64) error&#123; env := &amp;cb.Envelope&#123;&#125; proto.Unmarshal(regularMessage.Payload, env) // 从载荷中解析出信封结构 switch regularMessage.Class &#123; case ab.KafkaMessageRegular_NORMAL: // 普通交易消息 chain.ProcessNormalMsg(env) // 检查消息合法性，分应用链和系统链两种情况 commitNormalMsg(env) // 处理交易消息，满足条件则切块，并写入本地账本 case ab.KafkaMessageRegular_CONFIG: // 配置消息，包括通道头部类型为 CONFIG、CONFIG_UPDATE、ORDERER_TRANSACTION 三种 chain.ProcessConfigMsg(env) //检查消息合法性，分应用链和系统链两种情况 commitConfigMsg(env) // 切块，写入账本。如果是 ORDERER_TRANSACTION 消息，创建新的应用通道账本；如果是 CONFIG 消息，更新配置。&#125; 3.5.2 普通交易消息普通交易消息，会检查是否满足生成区块的条件，满足则产生区块并写入本地账本结构。通过内部的 commitNormalMsg(env) 方法来完成。 该方法主要调用 orderer/common/multichannel 模块中 BlockWriter 结构体的 CreateNextBlock(messages []cb.Envelope) cb.Block 方法和 WriteBlock(block *cb.Block, encodedMetadataValue []byte) 方法。 CreateNextBlock(messages []cb.Envelope) cb.Block 方法基本过程十分简单，创建新的区块，将传入的交易的信封结构直接序列化到 block.Data.Data[] 域中。 123456789101112131415161718192021// orderer/common/multichannel/blockwriter.gofunc (bw *BlockWriter) CreateNextBlock(messages []*cb.Envelope) *cb.Block &#123; previousBlockHash := bw.lastBlock.Header.Hash() data := &amp;cb.BlockData&#123; Data: make([][]byte, len(messages)), &#125; var err error for i, msg := range messages &#123; data.Data[i], err = proto.Marshal(msg) if err != nil &#123; logger.Panicf("Could not marshal envelope: %s", err) &#125; &#125; block := cb.NewBlock(bw.lastBlock.Header.Number+1, previousBlockHash) block.Header.DataHash = data.Hash() block.Data = data return block&#125; WriteBlock(block *cb.Block, encodedMetadataValue []byte) 方法则将 Kafka 相关的元数据也附加到区块结构中，添加区块的签名、最新配置的签名，并写入到本地账本。 12345678910// orderer/common/multichannel/blockwriter.gofunc (bw *BlockWriter) WriteBlock(block *cb.Block, encodedMetadataValue []byte) &#123; bw.committingBlock.Lock() bw.lastBlock = block go func() &#123; defer bw.committingBlock.Unlock() bw.commitBlock(encodedMetadataValue) &#125;()&#125; Kafka 相关的元数据（KafkaMetadata）包括： LastOffsetPersisted：上次消息的偏移量； LastOriginalOffsetProcessed：本条消息被重复处理时，最新的偏移量； LastResubmittedConfigOffset：上次提交的配置消息的偏移量。 3.5.3 配置交易消息首先会检查消息中配置版本号是否跟当前链上的配置版本号一致。如果不一致，则会更新后生成新的配置信封消息，扔回到后端的共识模块（如 Kafka），并且阻塞新的 Broadcast 消息直到重新提交的消息得到处理。代码片段如下： 12345678910111213// orderer/consensus/kafka/chain.goif regularMessage.ConfigSeq &lt; seq &#123; // 消息中配置版本并非最新版本 configEnv, configSeq, err := chain.ProcessConfigMsg(env) // For both messages that are ordered for the first time or re-ordered, we set original offset // to current received offset and re-order it. if err := chain.configure(configEnv, configSeq, receivedOffset); err != nil &#123; return fmt.Errorf("error re-submitting config message because = %s", err) &#125; chain.lastResubmittedConfigOffset = receivedOffset // Keep track of last resubmitted message offset chain.doneReprocessingMsgInFlight = make(chan struct&#123;&#125;) //Create the channel to block ingress messages return nil&#125; 如果版本一致，则调用内部的 commitConfigMsg(env) 方法根据信封结构来产生区块。 12345678910111213141516171819202122232425commitConfigMsg := func(message *cb.Envelope, newOffset int64) &#123; batch := chain.BlockCutter().Cut() // 尝试把收到的交易汇总 if batch != nil &#123; // 如果已经积累了一些交易，则先把它们打包为区块 block := chain.CreateNextBlock(batch) metadata := utils.MarshalOrPanic(&amp;ab.KafkaMetadata&#123; LastOffsetPersisted: receivedOffset - 1, LastOriginalOffsetProcessed: chain.lastOriginalOffsetProcessed, LastResubmittedConfigOffset: chain.lastResubmittedConfigOffset, &#125;) chain.WriteBlock(block, metadata) chain.lastCutBlockNumber++ &#125; chain.lastOriginalOffsetProcessed = newOffset block := chain.CreateNextBlock([]*cb.Envelope&#123;message&#125;) // 将配置交易生成区块 metadata := utils.MarshalOrPanic(&amp;ab.KafkaMetadata&#123; LastOffsetPersisted: receivedOffset, LastOriginalOffsetProcessed: chain.lastOriginalOffsetProcessed, LastResubmittedConfigOffset: chain.lastResubmittedConfigOffset, &#125;) chain.WriteConfigBlock(block, metadata) // 添加区块到系统链 chain.lastCutBlockNumber++ chain.timer = nil&#125; 由于每个配置消息会单独生成区块。因此，如果之前已经收到了一些普通交易消息，会先把这些消息生成区块。 接下来，调用 orderer/common/multichannel 模块中 BlockWriter 结构体的 CreateNextBlock(messages []cb.Envelope) cb.Block 方法和 WriteConfigBlock(block *cb.Block, encodedMetadataValue []byte) 方法来分别打包区块和更新账本结构，代码如下： 1234567891011// orderer/consensus/kafka/chain.gochain.lastOriginalOffsetProcessed = newOffsetblock := chain.CreateNextBlock([]*cb.Envelope&#123;message&#125;)metadata := utils.MarshalOrPanic(&amp;ab.KafkaMetadata&#123; LastOffsetPersisted: receivedOffset, LastOriginalOffsetProcessed: chain.lastOriginalOffsetProcessed, LastResubmittedConfigOffset: chain.lastResubmittedConfigOffset,&#125;)chain.WriteConfigBlock(block, metadata)chain.lastCutBlockNumber++chain.timer = nil 其中， WriteConfigBlock() 方法执行解析消息和处理的主要逻辑，核心代码如下所示。 123456789101112131415161718192021222324// orderer/common/multichannel/blockwriter.gofunc (bw *BlockWriter) WriteConfigBlock(block *cb.Block, encodedMetadataValue []byte)&#123; // 解析配置交易信封结构，每个区块中只有一个配置交易 ctx, err := utils.ExtractEnvelope(block, 0) // 解析载荷和通道头结构 payload, err := utils.UnmarshalPayload(ctx.Payload) chdr, err := utils.UnmarshalChannelHeader(payload.Header.ChannelHeader) // 按照配置交易内容，执行对应操作 switch chdr.Type &#123; // 排序后只有 ORDERER_TRANSACTION 和 CONFIG 两种类型消息 case int32(cb.HeaderType_ORDERER_TRANSACTION): // 新建应用通道 newChannelConfig, err := utils.UnmarshalEnvelope(payload.Data) // 创建新的本地账本结构并启动对应的轮询消息过程，实际调用 orderer/common/multichann el.Registrar.newChain(configtx *cb.Envelope) bw.registrar.newChain(newChannelConfig) case int32(cb.HeaderType_CONFIG): // 更新通道配置 configEnvelope, err := configtx.UnmarshalConfigEnvelope(payload.Data) bundle, err := bw.support.CreateBundle(chdr.ChannelId, configEnvelope.Config) bw.support.Update(bundle) &#125; // 将区块写入到本地账本结构 bw.WriteBlock(block, encodedMetadataValue) &#125; 3.6 Orderer 节点 Broadcast 请求的处理Broadcast，意味着客户端将请求消息（例如完成背书后的交易）通过 gRPC 接口发送给 Ordering 服务。Orderer 进行本地验证处理后，会转化为入队消息发给后端共识模块（如 Kafka）。 发给 Orderer 的 Broadcast 请求消息包括链码的实例化、调用；通道的创建、更新。 来自客户端的请求消息，会首先交给 orderer.common.server 包中 server 结构体的 Broadcast(srv ab.AtomicBroadcast_BroadcastServer) error 方法处理。该方法主要会调用到 orderer.common.broadcast 包中 handlerImpl 结构的 Handle(srv ab.AtomicBroadcast_BroadcastServer) error 方法。 handlerImpl 结构体十分重要，在 Orderer 整个处理过程中都会用到。 1234567type handlerImpl struct &#123; sm ChannelSupportRegistrar &#125;func (bh *handlerImpl) Handle(srv ab.AtomicBroadcast_BroadcastServer) error Broadcast 请求的整体处理过程如下图所示。 ​ 图 - Orderer 节点 Broadcast 处理过程 Handle(srv ab.AtomicBroadcast_BroadcastServer) error 方法会开启一个循环来从 srv 中读取请求消息并进行处理，直到结束。主要包括解析消息、处理消息（包括配置消息和非配置消息）和返回响应三个步骤。 核心代码如下所示（位于 orderer/common/broadcast/broadcast.go#handlerImpl.Handle() ）： 12345678910111213141516171819for &#123; msg, error := srv.Recv() // 从请求中提取一个 Envelope 消息 // 解析消息：判断是否为配置消息；获取对应本地账本结构：由通道头部中指定的通道 ID 决定，本地对应账 本结构不存在时（如新建应用通道）则由系统通道来处理 chdr, isConfig, processor, err := bh.sm.BroadcastChannelSupport(msg) // 检查是否被之前重新提交的消息阻塞 processor.WaitReady() // 对应的通道结构对消息进行处理 if !isConfig &#123; // 普通消息 configSeq, err := processor.ProcessNormalMsg(msg) //消息检查 processor.Order(msg, configSeq) //入队列操作 &#125;else&#123; // 配置消息，目前只有 CONFIG_UPDATE 类型，如创建、更新通道，或获取配置区块 config, configSeq, err := processor.ProcessConfigUpdateMsg(msg)// 合并配置更新消息 processor.Configure(config, configSeq) //入队列操作：相关处理后发给 Kafka &#125; srv.Send(&amp;ab.BroadcastResponse&#123;Status: cb.Status_SUCCESS&#125;) // 返回响应消息&#125; 分为三个步骤： 解析消息：判断是否为配置消息，决定消息应由哪个通道结构进行处理，注意对于创建应用通道消息，处理器指定为系统的通道结构； 处理消息：选用对应的通道结构对消息进行处理，包括普通消息和配置消息； 返回响应消息给请求方。 3.6.1 解析消息首先，解析消息，获取消息通道头、是否为配置消息、获取对应处理器结构（链结构）。 1chdr, isConfig, processor, err := bh.sm.BroadcastChannelSupport(msg) 实际上，会映射到 orderer.common.server 包中 broadcastSupport 结构体的 BroadcastChannelSupport(msg *cb.Envelope) (*cb.ChannelHeader, bool,broadcast.ChannelSupport, error) 方法，进一步调用到 orderer.common.multichannel 包中 Registrar 结构体的对应方法。 123456789101112131415161718192021// orderer/common/multichannel/registrar.gofunc (r *Registrar) BroadcastChannelSupport(msg *cb.Envelope) (*cb.ChannelHeader, bool, *ChainSupport, error) &#123; chdr, err := utils.ChannelHeader(msg) if err != nil &#123; return nil, false, nil, fmt.Errorf("could not determine channel ID: %s", err) &#125; cs, ok := r.chains[chdr.ChannelId] // 应用通道、系统通道 if !ok &#123; cs = r.systemChannel // 空，则默认为系统通道，如收到新建应用通道请求时，Orderer 本地并没有该应用通道结构 &#125; isConfig := false switch cs.ClassifyMsg(chdr) &#123; // 只有 CONFIG_UPDATE 会返回 ConfigUpdateMsg case msgprocessor.ConfigUpdateMsg: // CONFIG_UPDATE 消息，包括创建、更新通道，获取配置区块等 isConfig = true default: &#125; return chdr, isConfig, cs, nil&#125; channel 头部从消息信封结构中解析出来；是否为配置信息根据消息头中通道类型进行判断（是否为 cb.HeaderType_CONFIG_UPDATE）；通过字典结构查到对应的 ChainSupport 结构（应用通道、系统通道）作为处理器。之后，利用解析后的结果，分别对不同类型的消息（普通消息、配置消息）进行不同处理。 对于普通交易消息，主要执行如下两个操作：消息格式检查和入队列操作。 12configSeq, err := processor.ProcessNormalMsg(msg) //消息检查processor.Order(msg, configSeq) //入队列操作 消息检查方法会映射到 orderer.common.msgprocessor 包中 StandardChannel/SystemChannel 结构体的ProcessNormalMsg(env *cb.Envelope) (configSequint64, err error) 方法，以应用通道为例，实现如下。 123456// orderer/common/msgprocessor/standardchannel.gofunc (s *StandardChannel) ProcessNormalMsg(env *cb.Envelope) (configSeq uint64, err error)&#123; configSeq = s.support.Sequence() // 获取配置的序列号，映射到 common.configtx 包中 configManager 结构体的对应方法 err = s.filters.Apply(env) // 进行过滤检查，实现为 orderer.common.msgprocessor 包中 RuleSet 结构体的对应方法。 return&#125; 其中，过滤器会在创建 ChainSupport 结构时候初始化： 应用通道：orderer.common.mspprocessor 包中的CreateStandardChannelFilters(filterSupport channelconfig.Resources) *RuleSet 方法，包括 EmptyRejectRule、SizeFilter 和SigFilter（ChannelWriters 角色）。 系统通道：orderer.common.mspprocessor 包中的CreateSystemChannelFilters(chainCreator ChainCreator, ledgerResourceschannelconfig.Resources) *RuleSet 方法，包括 EmptyRejectRule、SizeFilter、SigFilter（ChannelWriters 角色）和 SystemChannelFilter。 入队列操作 入队列操作会根据 consensus 配置的不同映射到 orderer.consensus.solo 包或orderer.consensus.kafka 包中的方法。 以 kafka 情况为例，会映射到 chainImpl 结构体的对应方法。该方法会将消息进一步封装为sarama.ProducerMessage 类型消息，通过 enqueue 方法发给 Kafka 后端。 123456789101112131415// orderer/consensus/kafka/chain.go#chainImpl.Order(）func (chain *chainImpl) Order(env *cb.Envelope, configSeq uint64) error &#123; return chain.order(env, configSeq, int64(0))&#125;func (chain *chainImpl) order(env *cb.Envelope, configSeq uint64, originalOffset int64 ) error &#123; marshaledEnv, err := utils.Marshal(env) if err != nil &#123; return fmt.Errorf("cannot enqueue, unable to marshal envelope because = %s",err) &#125; if !chain.enqueue(newNormalMessage(marshaledEnv, configSeq, originalOffset)) &#123; return fmt.Errorf("cannot enqueue") &#125; return nil&#125; 3.6.2 处理配置交易消息对于配置交易消息（CONFIG_UPDATE 类型消息，包括创建、更新通道，获取配置区块等），处理过程与正常消息略有不同，包括合并配置更新消息和入队列操作两个操作。 合并配置更新 主要过程包括如下两个步骤： 12config, configSeq, err := processor.ProcessConfigUpdateMsg(msg) // 合并配置更新，生成新的配置信封结构processor.Configure(config, configSeq) //入队列操作，将生成的配置信封结构消息扔给后端队列（如Kafka) 其中，合并配置更新消息方法会映射到 orderer.common.msgprocessor 包中StandardChannel/SystemChannel 结构体的 ProcessConfigUpdateMsg(env *cb.Envelope)(configSeq uint64, err error) 方法，计算合并后的配置和配置编号。 以应用通道为例，实现如下。 123456789101112131415161718192021222324252627// orderer/common/msgprocessor/standardchannel.gofunc (s *StandardChannel) ProcessConfigUpdateMsg(env *cb.Envelope) (config *cb.Envelop e, configSeq uint64, err error) &#123; logger.Debugf("Processing config update message for channel %s", s.support.ChainID()) seq := s.support.Sequence() // 获取当前配置的版本号 err = s.filters.Apply(env) // 校验权限，是否可以更新配置 if err != nil &#123; return nil, 0, err &#125; // 根据输入的更新配置交易消息生成配置信封结构：Config 为更新后配置字典；LastUpdate 为输入的更新配置交易 // 最终调用 `common/configtx` 包下 `ValidatorImpl.ProposeConfigUpdate()` 方法。 configEnvelope, err := s.support.ProposeConfigUpdate(env) if err != nil &#123; return nil, 0, err &#125; // 生成签名的配置信封结构，通道头类型为 HeaderType_CONFIG。即排序后消息类型将由 CONFIG_UPDATE 变更为 CONFIG config, err = utils.CreateSignedEnvelope(cb.HeaderType_CONFIG, s.support.ChainID(), s.support.Signer(), configEnvelope, msgVersion, epoch) if err != nil &#123; return nil, 0, err &#125; err = s.filters.Apply(config) // 校验生成的配置消息是否合法 if err != nil &#123; return nil, 0, err &#125; return config, seq, nil&#125; 对于系统通道情况，除了调用普通通道结构的对应方法来处理普通的更新配置交易外，还会负责新建应用通道请求。 123456789101112131415161718192021222324// orderer/common/msgprocessor/systemchannel.gofunc (s *SystemChannel) ProcessConfigUpdateMsg(envConfigUpdate *cb.Envelope) (config *cb.Envelope, configSeq uint64, err error) &#123; channelID, err := utils.ChannelID(envConfigUpdate) if channelID == s.support.ChainID() &#123; // 更新系统通道的配置交易，与普通通道相同处理 return s.StandardChannel.ProcessConfigUpdateMsg(envConfigUpdate) &#125; // 从系统通道中获取当前最新的配置 // orderer/common/msgprocessor/systemchannel.go#DefaultTemplator.NewChannelConfig() bundle, err := s.templator.NewChannelConfig(envConfigUpdate) // 合并来自客户端的配置更新信封结构，创建配置信封结构 ConfigEnvelope newChannelConfigEnv, err := bundle.ConfigtxValidator().ProposeConfigUpdate(envConf igUpdate) // 封装新的签名信封结构，其 Payload.Data 是 newChannelConfigEnv newChannelEnvConfig, err := utils.CreateSignedEnvelope(cb.HeaderType_CONFIG, channelID, s.support.Signer(), newChannelConfigEnv, msgVersion, epoch) // 处理新建应用通道请求，封装为 ORDERER_TRANSACTION 类型消息 wrappedOrdererTransaction, err := utils.CreateSignedEnvelope(cb.HeaderType_ORDERER_TRANSACTION, s.support.ChainID(), s.support.Signer(), newChannelEnvConfig, msgVersion, epoch) s.StandardChannel.filters.Apply(wrappedOrdererTransaction) // 再次校验配置 // 返回封装后的签名信封结构 return wrappedOrdererTransaction, s.support.Sequence(), nil&#125; 入队列操作会根据 consensus 配置的不同映射到 orderer.consensus.solo 包或 orderer.consensus.kafka 包中的方法。以 kafka 情况为例，会映射到 chainImpl 结构体的 Configure(config cb.Envelope, configSeq uint64) 方法。该方法会调用 configure(config cb.Envelope, configSeq uint64, originalOffset int64) 方法，将消息进一步封装为 KafkaMessage_Regular 类型消息，通过 enqueue 方法发给 Kafka 后端。 12345678910111213// orderer/consensus/kafka/chain.gofunc (chain *chainImpl) configure(config *cb.Envelope, configSeq uint64, originalOffset int64) error &#123; marshaledConfig, err := utils.Marshal(config) if err != nil &#123; return fmt.Errorf("cannot enqueue, unable to marshal config because %s", err) &#125; // 封装为 `KafkaMessageRegular_CONFIG` 类型消息，并通过 producer 发给 Kafka if !chain.enqueue(newConfigMessage(marshaledConfig, configSeq, originalOffset)) &#123; return fmt.Errorf("cannot enqueue") &#125; return nil&#125; 其中，封装为 KafkaMessageRegular_CONFIG 类型消息过程十分简单。 12345678910111213// orderer/consensus/kafka/chain.gofunc newConfigMessage(config []byte, configSeq uint64, originalOffset int64) *ab.KafkaMessage &#123; return &amp;ab.KafkaMessage&#123; Type: &amp;ab.KafkaMessage_Regular&#123; Regular: &amp;ab.KafkaMessageRegular&#123; Payload: config, ConfigSeq: configSeq, Class: ab.KafkaMessageRegular_CONFIG, OriginalOffset: originalOffset, &#125;, &#125;, &#125;&#125; 之后 Orderer 将再次从 Kakfa 获取到共识（这里主要是排序）完成的 KafkaMessageRegular_CONFIG 消息，进行解析和处理。具体可以参考Orderer 节点对排序后消息的处理过程。 3.6.3 返回响应如果处理成功，则返回成功响应消息。 1srv.Send(&amp;ab.BroadcastResponse&#123;Status: cb.Status_SUCCESS&#125;) 3.7 Orderer 节点 Deliver 请求的处理Deliver，意味着客户端通过 gRPC 接口从 Ordering 服务获取数据（例如指定区块的数据）。 Orderer 节点收到请求消息，会首先交给 orderer.common.server 包中 server 结构体的 Deliver(srv ab.AtomicBroadcast_DeliverServer) error 方法处理。该方法进一步调用 orderer.common.deliver 包中 deliverServer 结构的 Handle(srv ab.AtomicBroadcast_DeliverServer) error 方法进行处理。 deliverServer 结构体十分重要，完成对 Deliver 请求的处理过程。 1234567type deliverServer struct &#123; sm SupportManager &#125;func (ds *deliverServer) Handle(srv ab.AtomicBroadcast_DeliverServer) error 整体处理过程如下图所示。 ​ Orderer 节点 Deliver 处理过程 Handle(srv ab.AtomicBroadcast_DeliverServer) error 方法会开启一个循环来从 srv 中不断读 取请求消息并进行处理，直到结束。 核心代码如下所示，包括提取消息和对消息进行处理两个步骤。 1234for &#123; envelope, err := srv.Recv() // 从请求中提取一个 Envelope 消息 ds.deliverBlocks(srv, envelope) // 对消息进行处理并答复，核心过程&#125; 可见，对单个请求的处理都在 deliverBlocks(srv ab.AtomicBroadcast_DeliverServer, envelope *cb.Envelope) 方法中。该方法的处理过程包括解析消息、检查合法性、发送区块以及返回响 应四个步骤。 3.7.1 解析消息首先，从请求的 Envelope 结构中提取载荷（Payload），进一步从载荷中提取通道头部信息。利用通道头部信息获取对应的本地链结构，并获取当前最新的配置序列号。 1234567891011// 提取载荷payload, err := utils.UnmarshalPayload(envelope.Payload)// 提取通道头chdr, err := utils.UnmarshalChannelHeader(payload.Header.ChannelHeader)// 获取链结构，映射到 orderer.common.multichannel 包中 Registrar 结构体中对应方法chain, ok := ds.sm.GetChain(chdr.ChannelId)// 获取当前配置序列号lastConfigSequence := chain.Sequence() 3.7.2 检查合法性包括对权限和 seekInfo 数据进行检查。首先，检查请求方是否对通道拥有读权限。 12345sf := msgprocessor.NewSigFilter(policies.ChannelReaders, chain.PolicyManager())if err := sf.Apply(envelope); err != nil &#123; logger.Warningf("[channel: %s] Received unauthorized deliver request from %s: %s",chdr.ChannelId, addr, err) return sendStatusReply(srv, cb.Status_FORBIDDEN)&#125; 接下来，从 Envelope 结构的 payload.data 域中解析出 seekInfo 结构，并检查其合法性。 1234567891011121314151617proto.Unmarshal(payload.Data, seekInfo)chain.Reader().Iterator(seekInfo.Start)// 检查 seekInfo 的cursor, number := chain.Reader().Iterator(seekInfo.Start)switch stop := seekInfo.Stop.Type.(type) &#123; case *ab.SeekPosition_Oldest: // 截止到最早的区块 stopNum = number case *ab.SeekPosition_Newest: // 截止到最新的区块 stopNum = chain.Reader().Height() - 1 case *ab.SeekPosition_Specified: // 截止到特定的区块 stopNum = stop.Specified.Number if stopNum &lt; number &#123; logger.Warningf("[channel: %s] Received invalid seekInfo message from %s: star t number %d greater than stop number %d", chdr.ChannelId, addr, number, stopNum) return sendStatusReply(srv, cb.Status_BAD_REQUEST) &#125;&#125; 3.7.3 发送区块在指定的起始和截止范围内，逐个从本地账本读取区块，并发送对应的区块数据，核心代码如下所示。 1234567for &#123; block, status := cursor.Next() // 获取区块 sendBlockReply(srv, block) // 发送区块 if stopNum == block.Header.Number &#123; break &#125;&#125; 3.7.4 返回响应如果处理成功，则返回成功响应消息。 1sendStatusReply(srv, cb.Status_SUCCESS) 3.8 客户端执行创建通道主要步骤包括： 客户端调用 sendCreateChainTransaction()，检查指定的配置交易文件，或者利用默认配 置，构造一个创建应用通道的配置交易结构，封装为 Envelope，指定 channel 头部类型 为 CONFIG_UPDATE。 客户端发送配置交易到 Ordering 服务。 Orderer 收到 CONFIG_UPDATE 消息后，检查指定的通道还不存在，则开始新建过程 （参考 orderer/configupdate/configupdate.go 文件），构造该应用通道的初始区块。 Orderer 首先检查通道应用（Application）配置中的组织都在创建的联盟 （Consortium）配置组织中。 之后从系统通道中获取 Orderer 相关的配置，并创建应用通道配置，对应 mod_policy 为系统通道配置中的联盟指定信息。 接下来根据 CONFIG_UPDATE 消息的内容更新获取到的配置信息。所有配置发生变更后版本号都要更新。 最后，创建签名 Proposal 消息（头部类型为 ORDERER_TRANSACTION），发送到系统通道中，完成应用通道的创建过程。 客户端利用 gRPC 通道从 Orderer 服务获取到该应用通道的初始区块（具体过程类似fetch 命令）。 客户端将收到的区块写入到本地的 chainID + “.block” 文件。这个文件后续会被需要加入到通道的节点使用。 3.9 客户端执行加入通道主要步骤包括： 客户端首先创建一个 ChaincodeSpec 结构，其 input 中的 Args 第一个参数是 CSCC.JoinChain（指定调用配置链码的操作），第二个参数为所加入通道的初始区块。 利用 ChaincodeSpec 构造一个 ChaincodeInvocationSpec 结构。 利用 ChaincodeInvocationSpec，创建 Proposal 结构并进行签名，channel 头部类型为 CONFIG。 客户端通过 gRPC 将 Proposal 签名后发给 Endorser（所操作的 Peer），调用 ProcessProposal(ctx context.Context, in *SignedProposal, opts …grpc.CallOption) (*ProposalResponse, error) 方法进行处理，主要通过配置系统链码进行本地链的初始化 工作。 初始化完成后，即可收到来自通道内的 Gossip 消息等。 其中，比较重要的数据结构包括 ChaincodeSpec、ChaincodeInvocationSpec、Proposal 等。 3.10 客户端执行链码安装链码安装过程​ 链码安装主要包括两个部分： 客户端封装安装消息； Peer 节点处理请求。 3.10.1 客户端封装安装消息客户端将链码的源码和环境等内容封装为一个链码安装打包文件（Chaincode Install Package，CIP），并传输到指定的 Peer 节点。此过程只需要跟 Peer 节点打交道。 主要步骤包括： 首先是构造带签名的提案结构（SignedProposal）。 调用 InitCmdFactory(isEndorserRequired, isOrdererRequired bool) ​ (*ChaincodeCmdFactory, error) 方法，初始化 EndoserClient（跟 Peer 通信）、 ​ BroadcastClient（跟 Orderer 通信）、Signer（签名操作）等辅助结构体。所有链 ​ 码子命令都会执行该过程，会根据需求具体初始化不同的结构。 然后根据命令行参数进行解析，判断是根据传入的打包文件来直接读取 ​ ChaincodeDeploymentSpec（CDS）结构，还是根据传入参数从本地链码源代码文 ​ 件来构造生成。 以本地重新构造情况为例，首先根据命令行中传入的路径、名称等信息，构造生成 ChaincodeSpec（CS）结构。 利用 ChaincodeSpec 结构，结合链码包数据生成一个 ChaincodeDeploymentSpec 结构（chainID 为空），调用本地的 install(msg proto.Message, cf *ChaincodeCmdFactory) error 方法。 install 方法基于传入的 ChaincodeDeploymentSpec 结构，构造一个对生命周期管理 系统链码（LSCC）调用的 ChaincodeSpec 结构，其中，Type 为 ChaincodeSpec_GOLANG，ChaincodeId.Name 为“lscc”，Input 为 “install”+ChaincodeDeploymentSpec。进一步地，构造了一个 LSCC 的 ChaincodeInvocationSpec（CIS）结构，对 ChaincodeSpec 结构进行封装。 基于 LSCC 的 ChaincodeInvocationSpec 结构，添加头部结构，生成一个提案 （Proposal）结构。其中，通道头部中类型为 ENDORSER_TRANSACTION，TxID 为对随机数+签名实体，进行 Hash。 对 Proposal 进行签名，转化为一个签名后的提案消息结构 SignedProposal。 将带签名的提案结构通过 EndorserClient 经由 gRPC 通道发送给 Peer 的 ProcessProposal(ctx context.Context, in *SignedProposal, opts …grpc.CallOption) (*ProposalResponse, error) 接口。 Peer 模拟运行生命周期链码的调用交易进行处理，检查格式、签名和权限等，通过则保 86客户端执行链码安装 存到本地文件系统。 3.11客户端执行链码实例化主要步骤包括： 首先，类似链码安装命令，需要创建一个 SignedProposal 消息。注意 instantiate 和upgrade 支持 policy、escc、vscc 等参数。LSCC 的 ChaincodeSpec 结构中，Input 中包括类型（“deploy”）、通道 ID、ChaincodeDeploymentSpec 结构、背书策略、escc 和vscc 等。 调用 EndorserClient，发送 gRPC 消息，将签名后的 Proposal 发给指定的 Peer 节点（Endorser），调用 ProcessProposal(ctx context.Context, in *SignedProposal, opts …grpc.CallOption) (*ProposalResponse, error) 方法，进行背书处理。节点会模拟运行LSCC 的调用交易，启动链码容器。实例化成功后会返回 ProposalResponse 消息（其中包括背书签名）。 根据 Peer 返回的 ProposalResponse 消息，创建一个 SignedTX（Envelop 结构的交易，带有签名）。 使用 BroadcastClient 将交易消息通过 gRPC 通道发给 Orderer，Orderer 会进行全网排序，并广播给 Peer 进行确认提交。 3.12 客户端执行链码调用基本过程如下： 首先，也是要创建一个 SignedProposal 消息。根据传入的各种参数，生成 ChaincodeSpec 结构（其中，Input 为传入的调用参数）。然后，根据 ChaincodeSpec、chainID、签名实体等，生成 ChaincodeInvocationSpec 结构。进而封装生成 Proposal 结构（通道头部中类型为ENDORSER_TRANSACTION），并进行签名。 调用 EndorserClient，发送 gRPC 消息，将签名后的 Proposal 发给指定的 Peer 节点 （Endorser），调用 ProcessProposal(ctx context.Context, in SignedProposal, opts…grpc.CallOption) (*ProposalResponse, error) 方法，进行背书处理。节点会模拟运行链码调用交易，成功后会返回 ProposalResponse 消息（带有背书签名）。 根据 Peer 返回的 ProposalResponse 消息，创建一个 SignedTX（Envelop 结构的交易，带有签名）。 使用 BroadcastClient 将交易消息通过 gRPC 通道发给 Orderer 进行全网排序并广播给Peer 进行确认提交。 注意 invoke 是异步操作，invoke 成功只能保证交易已经进入 Orderer 进行排序，但无法保证 最终写到账本中（例如交易未通过 Committer 验证而被拒绝）。需要通过 eventHub 或查询 方式来进行确认交易是否最终写入到账本上。 3.13 客户端执行链码查询主要过程如下: 根据传入的各种参数，最终构造签名提案，通过 endorserClient 发送给指定的 Peer。 成功的话，获取到 ProposalResponse，打印出 proposalResp.Response.Payload 内容。 需要注意 invoke 和 query 的区别，query 不需要创建 SignedTx 发送到 Orderer，而且会返回 查询的结果。 Fabric词汇Anchor Peer - 锚节点A peer node on a channel that all other peers can discover and communicate with. Each Member on a channel has an anchor peer (or multiple anchor peers to prevent single point of failure), allowing for peers belonging to different Members to discover all existing peers on a channel. 锚节点是通道中能被所有对等节点探测、并能与之进行通信的一种对等节点。通道中的每个成员都有一个（或多个，以防单点故障）锚节点，允许属于不同成员身份的节点来发现通道中存在的其它节点。 Block - 区块An ordered set of transactions that is cryptographically linked to the preceding block(s) on a channel. 在一个通道上，（区块是）一组有序交易的集合。区块往往通过密码学手段（Hash 值）连接到前导区块。 区块是一组有序的交易集合，在通道中经过加密（哈希加密）后与前序区块连接。 Chain - 链The ledger’s chain is a transaction log structured as hash-linked blocks of transactions. Peers receive blocks of transactions from the ordering service, mark the block’s transactions as valid or invalid based on endorsement policies and concurrency violations, and append the block to the hash chain on the peer’s file system. chain就是block之间以hash连接为结构的交易日志。peer从order service接收交易block，并根据背书策略和并发冲突标记block上的交易是否有效，然后将该block追加到peer文件系统中的hash chain上。 账本的链是一个交易区块经过“哈希连接”结构化的交易日志。对等节点从排序服务收到交易区块，基于背书策略和并发冲突来标注区块的交易为有效或者无效状态，并且将区块追加到对等节点文件系统的哈希链中。 Chaincode - 链码Chaincode is software, running on a ledger, to encode assets and the transaction instructions (business logic) for modifying the assets. 链码是一个运行在账本上的软件，它可以对资产进行编码，其中的交易指令（或者叫业务逻辑）也可以用来修改资产。 Channel - 通道A channel is a private blockchain overlay on a Fabric network, allowing for data isolation and confidentiality. A channel-specific ledger is shared across the peers in the channel, and transacting parties must be properly authenticated to a channel in order to interact with it. Channels are defined by a Configuration-Block. 通道是构建在“Fabric”网络上的私有区块链，实现了数据的隔离和保密。通道特定的账本在通道中是与所有对等节点共享的，并且交易方必须通过该通道的正确验证才能与账本进行交互。通道是由一个“配置块”来定义的。 Commitment - 提交Each Peer on a channel validates ordered blocks of transactions and then commits (writes-appends) the blocks to its replica of the channel Ledger. Peers also mark each transaction in each block as valid or invalid. 一个通道中的每个对等节点都会验证交易的有序区块，然后将区块提交（写或追加）至该通道上账本的各个副本。对等节点也会标记每个区块中的每笔交易的状态是有效或者无效。 Consensus - 共识A broader term overarching the entire transactional flow, which serves to generate an agreement on the order and to confirm the correctness of the set of transactions constituting a block. 共识是贯穿整个交易流程的广义术语，其用于产生一个对于排序的同意书和确认构成区块的交易集的正确性。 Current State - 当前状态The current state of the ledger represents the latest values for all keys ever included in its chain transaction log. Peers commit the latest values to ledger current state for each valid transaction included in a processed block. Since current state represents all latest key values known to the channel, it is sometimes referred to as World State. Chaincode executes transaction proposals against current state data. ledger的current state表示其chain交易log中所有key的最新值。peer会将处理过的block中的每个交易对应的修改value提交到ledger的current state，由于current state表示channel所知的所有最新的k-v，所以current state也被称为World State。Chaincode执行交易proposal就是针对的current state。 Dynamic Membership - 动态成员Fabric supports the addition-removal of members, peers, and ordering service nodes, without compromising the operationality of the overall network. Dynamic membership is critical when business relationships adjust and entities need to be added-removed for various reasons. Fabric支持动态添加-移除members、peers和ordering服务节点，而不会影响整个网络的操作性。当业务关系调整或因各种原因需添加-移除实体时，Dynamic Membership至关重要。 Endorsement - 背书Refers to the process where specific peer nodes execute a transaction and return a YES-NO response to the client application that generated the transaction proposal. Chaincode applications have corresponding endorsement policies, in which the endorsing peers are specified. Endorsement 是指一个peer执行一个交易并返回YES-NO给生成交易proposal的client app 的过程。chaincode具有相应的endorsement policies，其中指定了endorsing peer。 Endorsement policy - 背书策略Defines the peer nodes on a channel that must execute transactions attached to a specific chaincode application, and the required combination of responses (endorsements). A policy could require that a transaction be endorsed by a minimum number of endorsing peers, a minimum percentage of endorsing peers, or by all endorsing peers that are assigned to a specific chaincode application. Policies can be curated based on the application and the desired level of resilience against misbehavior (deliberate or not) by the endorsing peers. A distinct endorsement policy for install and instantiate transactions is also required. Endorsement policy定义了依赖于特定chaincode执行交易的channel上的peer和响应结果（endorsements）的必要组合条件（即返回Yes或No的条件）。Endorsement policy可指定对于某一chaincode，可以对交易背书的最小背书节点数或者最小背书节点百分比。背书策略由背书节点基于应用程序和对抵御不良行为的期望水平来组织管理。在install和instantiate Chaincode（deploy tx）时需要指定背书策略。 Fabric-caFabric-ca is the default Certificate Authority component, which issues PKI-based certificates to network member organizations and their users. The CA issues one root certificate (rootCert) to each member, one enrollment certificate (eCert) to each authorized user, and a number of transaction certificates (tCerts) for each eCert. Fabric-ca是默认的证书管理组件，它向网络成员及其用户颁发基于PKI的证书。CA为每个成员颁发一个根证书（rootCert），为每个授权用户颁发一个注册证书（eCert），为每个注册证书颁发大量交易证书（tCerts）。 Genesis Block - 初始区块The configuration block that initializes a blockchain network or channel, and also serves as the first block on a chain. Genesis Block是初始化区块链网络或channel的配置区块，也是链上的第一个区块。 Gossip Protocol - Gossip协议The gossip data dissemination protocol performs three functions: 1) manages peer discovery and channel membership; 2) disseminates ledger data across all peers on the channel; 3) syncs ledger state across all peers on the channel. Refer to the Gossip topic for more details. Gossip数据传输协议有三项功能：1）管理peer发现和channel成员；2）channel上的所有peer间广播账本数据；3）channel上的所有peer间同步账本数据。 Initialize - 初始化A method to initialize a chaincode application. 一个初始化chaincode程序的方法。 Install - 安装The process of placing a chaincode on a peer’s file system. 将chaincode放到peer的文件系统的过程。（译注：即将ChaincodeDeploymentSpec信息存到chaincodeInstallPath-chaincodeName.chainVersion文件中） Instantiate - 实例化The process of starting a chaincode container. 启动chaincode容器的过程。（译注：在lccc中将ChaincodeData保存到state中，然后deploy Chaincode并执行Init方法） Invoke - 调用Used to call chaincode functions. Invocations are captured as transaction proposals, which then pass through a modular flow of endorsement, ordering, validation, committal. The structure of invoke is a function and an array of arguments. 用于调用chaincode内的函数。Chaincode invoke就是一个交易proposal，然后执行模块化的流程（背书、共识、 验证、 提交）。invoke的结构就是一个函数和一个参数数组。 Leading Peer - 主导节点Each Member can own multiple peers on each channel that it subscribes to. One of these peers is serves as the leading peer for the channel, in order to communicate with the network ordering service on behalf of the member. The ordering service “delivers” blocks to the leading peer(s) on a channel, who then distribute them to other peers within the same member cluster. 每一个Member在其订阅的channel上可以拥有多个peer，其中一个peer会作为channel的leading peer代表该Member与ordering service通信。ordering service将block传递给leading peer，该peer再将此block分发给同一member下的其他peer。 Ledger - 账本A ledger is a channel’s chain and current state data which is maintained by each peer on the channel. Ledger是个channel的chain和由channel中每个peer维护的world state。（这个解释有点怪） Member - 成员A legally separate entity that owns a unique root certificate for the network. Network components such as peer nodes and application clients will be linked to a member. 拥有网络唯一根证书的合法独立实体。像peer节点和app client这样的网络组件会链接到一个Member。 Membership Service Provider - MSPThe Membership Service Provider (MSP) refers to an abstract component of the system that provides credentials to clients, and peers for them to participate in a Hyperledger Fabric network. Clients use these credentials to authenticate their transactions, and peers use these credentials to authenticate transaction processing results (endorsements). While strongly connected to the transaction processing components of the systems, this interface aims to have membership services components defined, in such a way that alternate implementations of this can be smoothly plugged in without modifying the core of transaction processing components of the system. MSP是指为client和peer提供证书的系统抽象组件。Client用证书来认证他们的交易；peer用证书认证其交易背书。该接口与系统的交易处理组件密切相关，旨在使已定义的成员身份服务组件以这种方式顺利插入而不会修改系统的交易处理组件的核心。 Membership Services - 成员服务Membership Services authenticates, authorizes, and manages identities on a permissioned blockchain network. The membership services code that runs in peers and orderers both authenticates and authorizes blockchain operations. It is a PKI-based implementation of the Membership Services Provider (MSP) abstraction. 成员服务在许可的区块链网络上认证、授权和管理身份。在peer和order中运行的成员服务的代码都会认证和授权区块链操作。它是基于PKI的MSP实现。 The fabric-ca component is an implementation of membership services to manage identities. In particular, it handles the issuance and revocation of enrollment certificates and transaction certificates. fabric-ca组件实现了成员服务，来管理身份。特别的，它处理ECert和TCert的颁发和撤销。 An enrollment certificate is a long-term identity credential; a transaction certificate is a short-term identity credential which is both anonymous and un-linkable. ECert是长期的身份凭证；TCert是短期的身份凭证，是匿名和不可链接的。 Ordering Service - 排序服务或共识服务A defined collective of nodes that orders transactions into a block. The ordering service exists independent of the peer processes and orders transactions on a first-come-first-serve basis for all channel’s on the network. The ordering service is designed to support pluggable implementations beyond the out-of-the-box SOLO and Kafka varieties. The ordering service is a common binding for the overall network; it contains the cryptographic identity material tied to each Member. 将交易排序放入block的节点的集合。ordering service独立于peer流程之外，并以先到先得的方式为网络上所有的channel作交易排序。ordering service支持可插拔实现，目前默认实现了SOLO和Kafka。ordering service是整个网络的公用binding，包含与每个Member相关的加密材料。 Peer - 节点A network entity that maintains a ledger and runs chaincode containers in order to perform read-write operations to the ledger. Peers are owned and maintained by members. 一个网络实体，维护ledger并运行Chaincode容器来对ledger执行read-write操作。peer由Member拥有和维护。 Policy - 策略There are policies for endorsement, validation, block committal, chaincode management and network-channel management. 有背书策略，校验策略，区块提交策略，Chaincode管理策略和网络-通道管理策略。 Proposal - 提案A request for endorsement that is aimed at specific peers on a channel. Each proposal is either an instantiate or an invoke (read-write) request. 一种针对channel中某peer的背书请求。每个proposal要么是Chaincode instantiate要么是Chaincode invoke。 Query - 查询A query requests the value of a key(s) against the current state. 对于current state中某个key的value的查询请求。 Software Development Kit - SDKThe Hyperledger Fabric client SDK provides a structured environment of libraries for developers to write and test chaincode applications. The SDK is fully configurable and extensible through a standard interface. Components, including cryptographic algorithms for signatures, logging frameworks and state stores, are easily swapped in and out of the SDK. The SDK API uses protocol buffers over gRPC for transaction processing, membership services, node traversal and event handling applications to communicate across the fabric. The SDK comes in multiple flavors - Node.js, Java. and Python. SDK为开发人员提供了一个结构化的库环境，用于编写和测试链码应用程序。SDK完全可以通过标准接口实现配置和扩展，像签名的加密算法、日志框架和state存储这样的组件都可以轻松地实现替换。SDK API使用gRPC进行交易处理，成员服务、节点遍历以及事件处理都是据此与fabric通信。目前SDK支持Node.js、Java和Python。 State Database - stateDBCurrent state data is stored in a state database for efficient reads and queries from chaincode. These databases include levelDB and couchDB. 为了从Chaincode中高效的读写，Current state 数据存储在stateDB中，包括levelDB和couchDB。 System Chain - 系统链Contains a configuration block defining the network at a system level. The system chain lives within the ordering service, and similar to a channel, has an initial configuration containing information such as: MSP information, policies, and configuration details. Any change to the overall network (e.g. a new org joining or a new ordering node being added) will result in a new configuration block being added to the system chain. 包含在系统级定义网络的配置区块。系统链存在于ordering service中，与channel类似，具有包含以下信息的初始配置：MSP信息、策略和信息配置。对整个网络的任何变化（例如新的Org加入或者添加新的Ordering节点）将导致新的配置区块被添加到系统链。 The system chain can be thought of as the common binding for a channel or group of channels. For instance, a collection of financial institutions may form a consortium (represented through the system chain), and then proceed to create channels relative to their aligned and varying business agendas. 系统链可看做是一个channel或一组channel的公用binding。例如，金融机构的集合可以形成一个财团（以system chain表示），然后根据其相同或不同的业务创建channel。 Transaction - 交易An invoke or instantiate operation. Invokes are requests to read-write data from the ledger. Instantiate is a request to start a chaincode container on a peer. Chaincode的invoke或instantiate操作。Invoke是从ledger中请求read-write set；Instantiate是请求在peer上启动Chaincode容器。]]></content>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[malloc、calloc、realloc的区别]]></title>
    <url>%2F2019%2F01%2F24%2Fmalloc%2F</url>
    <content type="text"><![CDATA[C语言跟内存申请相关的函数主要有 alloca、calloc、malloc、free、realloc等. alloca是向栈申请内存,因此无需释放. malloc分配的内存是位于堆中的,并且没有初始化内存的内容,因此基本上malloc之后,调用函数memset来初始化这部分的内存空间. calloc则将初始化这部分的内存,设置为0. realloc则对malloc申请的内存进行大小的调整. 申请的内存最终需要通过函数free来释放. 当程序运行过程中malloc了,但是没有free的话,会造成内存泄漏.一部分的内存没有被使用,但是由于没有free,因此系统认为这部分内存还在使用,造成不断的向系统申请内存,使得系统可用内存不断减少.但是内存泄漏仅仅指程序在运行时,程序退出时,OS将回收所有的资源.因此,适当的重起一下程序,有时候还是有点作用.【attention】 三个函数的申明分别是: void malloc(unsigned size); void realloc(void ptr, unsigned newsize); void calloc(size_t numElements, size_t sizeOfElement); 都在stdlib.h函数库内，它们的返回值都是请求系统分配的地址,如果请求失败就返回NULL. (1)函数malloc() 在内存的动态存储区中分配一块长度为size字节的连续区域，参数size为需要内存空间的长度，返回该区域的首地址. (2)函数calloc() 与malloc相似,参数sizeOfElement为申请地址的单位元素长度,numElements为元素个数，即在内存中申请numElementssizeOfElement字节大小的连续地址空间. (3)函数realloc() 给一个已经分配了地址的指针重新分配空间,参数ptr为原有的空间地址,newsize是重新申请的地址长度. 区别: (1)函数malloc不能初始化所分配的内存空间,而函数calloc能.如果由malloc()函数分配的内存空间原来没有被使用过，则其中的每一位可能都是0;反之, 如果这部分内存曾经被分配过,则其中可能遗留有各种各样的数据.也就是说，使用malloc()函数的程序开始时(内存空间还没有被重新分配)能正常进行,但经过一段时间(内存空间还已经被重新分配)可能会出现问题. (2)函数calloc() 会将所分配的内存空间中的每一位都初始化为零,也就是说,如果你是为字符类型或整数类型的元素分配内存,那么这些元素将保证会被初始化为0;如果你是为指针类型的元素分配内存,那么这些元素通常会被初始化为空指针;如果你为实型数据分配内存,则这些元素会被初始化为浮点型的零. (3)函数malloc向系统申请分配指定size个字节的内存空间.返回类型是 void类型.void表示未确定类型的指针.C,C++规定，void 类型可以强制转换为任何其它类型的指针. (4)realloc可以对给定的指针所指的空间进行扩大或者缩小，无论是扩张或是缩小，原有内存的中内容将保持不变.当然，对于缩小，则被缩小的那一部分的内容会丢失.realloc并不保证调整后的内存空间和原来的内存空间保持同一内存地址.相反，realloc返回的指针很可能指向一个新的地址. (5)realloc是从堆上分配内存的.当扩大一块内存空间时，realloc()试图直接从堆上现存的数据后面的那些字节中获得附加的字节，如果能够满足，自然天下太平；如果数据后面的字节不够，问题就出来了，那么就使用堆上第一个有足够大小的自由块，现存的数据然后就被拷贝至新的位置，而老块则放回到堆上.这句话传递的一个重要的信息就是数据可能被移动. reference]]></content>
      <tags>
        <tag>技术 编程语言 C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C时间戳]]></title>
    <url>%2F2019%2F01%2F12%2FC_time%2F</url>
    <content type="text"><![CDATA[clock()、time()、clock_gettime()和gettimeofday()函数的用法和区别1.精确度比较: 以下是各种精确度的类型转换:1秒=1000毫秒(ms), 1毫秒=1/1000秒(s)；1秒=1000000 微秒(μs), 1微秒=1/1000000秒(s)；1秒=1000000000 纳秒(ns),1纳秒=1/1000000000秒(s)； clock()函数的精确度是10毫秒(ms)times()函数的精确度是10毫秒(ms)gettimofday()函数的精确度是微秒(μs)clock_gettime()函数的计量单位为十亿分之一，也就是纳秒(ns) 详情]]></content>
      <tags>
        <tag>技术 C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL常用API]]></title>
    <url>%2F2019%2F01%2F04%2Fstl%2F</url>
    <content type="text"><![CDATA[序列容器常用容器：array、vector、deque、list、queue、stack要求：序列的元素必须是严格的线性顺序排序。因此序列中的元素具有确定的顺序，可以执行将值插入到特定位置、删除特定区间等操作。 array具体语法参考：http://www.cplusplus.com/reference/array/array/ vector具体语法参考：http://www.cplusplus.com/reference/vector/vector/ deque具体语法参考：http://www.cplusplus.com/reference/deque/deque/ list具体语法参考：http://www.cplusplus.com/reference/list/list/ queue（适配器）具体语法参考：http://www.cplusplus.com/reference/queue/queue/ stack(适配器)具体语法参考：http://www.cplusplus.com/reference/stack/stack/ C/C++STL常用容器用法总结：https://blog.csdn.net/weixin_41162823/article/details/79759081 关联容器关联容器与序列容器有着根本性的不同，序列容器的元素是按照在容器中的位置来顺序保存和访问的，而关联容器的元素是按关键元素来保存和访问的。关联容器支持高效的关键字查找与访问。两个主要的关联容器类型是map与set。 1.set1.1 简介：set里面每个元素只存有一个key，它支持高效的关键字查询操作。set对应数学中的“集合”。 具体语法参考：http://www.cplusplus.com/reference/set/set/ 1.2 特点： 储存同一类型的数据元素（这点和vector、queue等其他容器相同）每个元素的值都唯一（没有重复的元素）根据元素的值自动排列大小（有序性）无法直接修改元素高效的插入删除操作1.3 声明：set a set a={0,1,6,2,3};for(auto it = a.begin();it != a.end();it++) cout &lt;&lt; *it;//输出012361.4 常用函数 以下设 set a,其中a是T类型的set容器。 表达式 返回类型 说明 a.begin() 返回指向第一个元素的迭代器 a.end() 返回指向超尾的迭代器 a.clear() 清空容器a a.empty() 判断容器是否为空 a.size() 返回当前容器元素个数 a.count(x) 返回容器a中元素x的个数 1.6 插入元素： a.insert(x) :其中a为set型容器，x为T型变量 set a={0,1,2,9}; a.insert(6); for(auto it = a.begin();it != a.end();it++) cout &lt;&lt; it;//输出01269a.insert(first,second):其中first为指向区间左侧的迭代器，second为指向右侧的迭代器。作用是将first到second区间内元素插入到a（左闭右开）。set a = {0,1,2,9};set b = {3,4,5};auto first = b.begin();auto second = b.end();a.insert(first,second);for(auto it = a.begin();it != a.end();it++) cout &lt;&lt; it;插入元素会自动插入到合适的位置，使整个集合有序 1.7 删除元素： a.erase(x)：删除建值为x的元素a.erase(first,second)：删除first到second区间内的元素（左闭右开）a.erase(iterator):删除迭代器指向的元素set中的删除操作是不进行任何的错误检查的，比如定位器的是否合法等等，所以用的时候自己一定要注意。1.8 lower_bound 和 upper_bound 迭代器： lower_bound（x1）:返回第一个不小于键参数x1的元素的迭代器upper_bound（x2）:返回最后一个大于键参数x2的元素的迭代器由以上俩个函数，可以得到一个目标区间，即包含集合中从’x1’到’x2’的所有元素 #include #include #includeusing namespace std;int main(){ set a = {0,1,2,5,9}; auto it2 = a.lower_bound(2);//返回指向第一个大于等于x的元素的迭代器 auto it = a.upper_bound(2);//返回指向第一个大于x的元素的迭代器 cout &lt;&lt; it2 &lt;&lt; endl;//输出为2 cout &lt;&lt; it &lt;&lt; endl;//输出为5 return 0;}1.9 set_union() 与 set_intersection() set_union():对集合取并集 set_union()函数接受5个迭代器参数。前两个迭代器定义了第一个集合的区间，接下来的俩个迭代器定义了第二个集合的区间，最后一个迭代器是输出迭代器，指出将结果集合复制到什么位置。例如：要将A与B的集合复制到C中，可以这样写： #include #include #includeusing namespace std;int main(){ set A = {1,2,3}, B= {2,4,5},C; set_union(A.begin(),A.end(),B.begin(),B.end(), insert_iterator&lt;set &gt;(C,C.begin())); for(auto it = C.begin();it != C.end();it++) cout &lt;&lt; *it &lt;&lt;” “; return 0;}注意： 其中第五个参数不能写C.begin(),原因有两个：首先，关联集合将建看作常量，所以C.begin()返回的迭代器是常量迭代器，不能作为输出迭代器(详情请参考迭代器相关概念)。其次，与copy()相同，set_union()将覆盖容器中已有的数据，并且要求容器用足够的空间容纳新信息，而C不满足，因为它是空的。 解决方法：可以创建一个匿名的insert_iterator,将信息复制给C。如上述代码所为。另一种方法如下： set_union(A.begin(),A.end(),B.begin(),B.end(), inserter(C,C.begin()));//调用inserterset_intersection():对集合取交集，它的接口与set_union()相同。 附：使用set_union()和set_intersection()还有另一种技巧。由于需要五个迭代器，看起来会很累赘和麻烦，如果多次使用会增加出错的几率，所以我们可以试试用宏定义的方法来简化代码。如下： #include #include #includeusing namespace std; #define ALL(x) x.begin(),x.end() #define INS(x) inserter(x,x.begin())int main(){ set A = {1,2,3}, B= {2,4,5},C; set_union(ALL(A),ALL(B),INS(C)); for(auto it = C.begin();it != C.end();it++) cout &lt;&lt; *it &lt;&lt;” “; return 0;}其中使用到了宏定义。1.10 set的几个问题： （1）为何map和set的插入删除效率比用其他序列容器高？ 因为对于关联容器来说，不需要做内存拷贝和内存移动。set容器内所有元素都是以节点的方式来存储，其节点结构和链表差不多，指向父节点和子节点。因此插入的时候只需要稍做变换，把节点的指针指向新的节点就可以了。删除的时候类似，稍做变换后把指向删除节点的指针指向其他节点也OK了。这里的一切操作就是指针换来换去，和内存移动没有关系。 （2）为何每次insert之后，以前保存的iterator不会失效？ iterator这里就相当于指向节点的指针，内存没有变，指向内存的指针怎么会失效呢(当然被删除的那个元素本身已经失效了)。相对于vector来说，每一次删除和插入，指针都有可能失效，调用push_back在尾部插入也是如此。因为为了保证内部数据的连续存放，iterator指向的那块内存在删除和插入过程中可能已经被其他内存覆盖或者内存已经被释放了。即使时push_back的时候，容器内部空间可能不够，需要一块新的更大的内存，只有把以前的内存释放，申请新的更大的内存，复制已有的数据元素到新的内存，最后把需要插入的元素放到最后，那么以前的内存指针自然就不可用了。特别时在和find等算法在一起使用的时候，牢记这个原则：不要使用过期的iterator。 （3）当数据元素增多时，set的插入和搜索速度变化如何？ 如果你知道log2的关系你应该就彻底了解这个答案。在set中查找是使用二分查找，也就是说，如果有16个元素，最多需要比较4次就能找到结果，有32个元素，最多比较5次。那么有10000个呢？最多比较的次数为log10000，最多为14次，如果是20000个元素呢？最多不过15次。看见了吧，当数据量增大一倍的时候，搜索次数只不过多了1次，多了1/14的搜索时间而已。你明白这个道理后，就可以安心往里面放入元素了。 2.map2.1 简介：如果说set对应数学中的“集合”，那么map对应的就是“映射”。map是一种key-value型容器，其中key是关键字，起到索引作用，而value就是其对应的值。与set不同的是它支持下标访问。头文件是 具体语法参考：http://www.cplusplus.com/reference/map/map/ 2.2 特点： 增加和删除节点对迭代器的影响很小(高效的插入与删除)快速的查找（同set）自动建立key-value的对应，key和value可以是任何你需要的类型可以根据key修改value的记录支持下标[]操作2.3 声明：map&lt;T1,T2&gt; m 其中T1是key类型，T2是value类型，m就是一个T1-T2的key-value。 map&lt;string,int&gt; m;//声明一个key为string，value为int的map型容器下述代码更清楚的解释了map容器的特点： #include #includeusing namespace std;int main(){ map&lt;string,int&gt; m; m[“abc”] = 5; m[“cdf”] = 6; m[“b”] = 1; for(auto it = m.begin();it != m.end();it++) cout &lt;&lt; it-&gt;first &lt;&lt;” “ &lt;&lt; it-&gt;second &lt;&lt; endl; return 0;}在上述代码中，m容器被按照key的字典序升序排列了，而且我们可以通过将key当作索引来获取value的值。（同时这也是一种插入方法） 2.4 插入元素： 使用insert()函数插入pair类型的元素使用下标操作向map容器中插入元素map&lt;string,int&gt; m; m.insert(make_pair(“b”,6));//insert插入 m[“a”] = 5;//使用下标插入2.5 删除元素： erase(key):删除键为key的元素erase(it):删除迭代器it所指向的元素 #include #includeusing namespace std;int main(){ map&lt;string,int&gt; m; m.insert(make_pair(“b”,6)); m[“a”] = 5; m[“c”] = 5; m[“d”] = 5; m[“e”] = 5; m.erase(&quot;d&quot;); auto pr = m.begin(); m.erase(pr); for(auto it = m.begin();it != m.end();it++) cout &lt;&lt; it-&gt;first &lt;&lt;&quot; &quot; &lt;&lt; it-&gt;second &lt;&lt; endl; return 0; }2.6 map容器的遍历： 使用迭代器遍历（代码如上）注：使用迭代器遍历map容器，其中每一个元素可以看成是pair类型的，访问第一个位置的key值可以用it-&gt;first访问，第二个位置value的值可以用it-&gt;second访问，其中it是指向该元素的迭代器。2.7 常用函数： 下表中m为map类型的容器，it为和m同类型的迭代器，key表示该类型的一个键。 表达式 返回类型 说明 m.Count(key) 返回map中key出现的次数（0或1） m.find(key) 迭代器 返回指向key位置的迭代器.若无则返回m.end() m.insert(make_pair( ) ) 插入一个元素(必须以pair形式插入) m.erase(it) 删除迭代器it所指向的元素 m.erase(key) 删除键值为key的元素 m.size() 返回m中元素的个数 m.clear() 清空m容器 m.empty() bool 判断容器是否为空。空则返回true m.lower_bound(key) 迭代器 返回指向第一个键值不小于key的元素的迭代器 m.upper_bound(key) 迭代器 返回指向第一个键值大于key的元素的迭代器]]></content>
      <tags>
        <tag>技术 技术 编程语言 C++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL远程连接问题]]></title>
    <url>%2F2019%2F01%2F04%2Fmysql_1%2F</url>
    <content type="text"><![CDATA[如何让MySQL可以远程连接1.本地防火墙是否关闭 ufw status; 2.mysql配置文件my.cnf 注释掉 #bind 127.0.0.1 绑定本地地址 3.MySQL数据库user远程权限 grant all privileges on . to ‘root‘@’%’ identified by ‘123456’ with grant option;flush privileges;]]></content>
      <tags>
        <tag>mysql 数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11新特性]]></title>
    <url>%2F2018%2F12%2F27%2Fc%2B%2B11featrues%2F</url>
    <content type="text"><![CDATA[1.Lambda 表达式Lambda 表达式就是用于创建匿名函数的。为什么说 lambda 表达式如此激动人心呢？举一个例子。标准 C++ 库中有一个常用算法的库，其中提供了很多算法函数，比如 sort() 和 find()。这些函数通常需要提供一个“谓词函数 predicate function”。所谓谓词函数，就是进行一个操作用的临时函数。比如 find() 需要一个谓词，用于查找元素满足的条件；能够满足谓词函数的元素才会被查找出来。这样的谓词函数，使用临时的匿名函数，既可以减少函数数量，又会让代码变得清晰易读。 1[capture](parameters)-&gt;return-type &#123;body&#125; 最简单的例子如下： 123456789#include &lt;algorithm&gt;#include &lt;cmath&gt; void abssort(float *x, unsigned N)&#123; std::sort(x, x + N, [](float a, float b) &#123; return std::abs(a) &lt; std::abs(b); &#125;);&#125; 其中需要注意： 返回值类型-&gt;return-type可以省略，由语言自动推导，但前提是只有当 lambda 表达式中的语句“足够简单”，才能自动推断返回值类型。 引入 lambda 表达式的前导符是一对方括号，称为 lambda 引入符（lambda-introducer）。lambda 表达式可以使用与其相同范围 scope 内的变量。这个引入符的作用就是表明，其后的 lambda 表达式以何种方式使用（正式的术语是“捕获”）这些变量（这些变量能够在 lambda 表达式中被捕获，其实就是构成了一个闭包）。 捕获类型可以以下类型： [] // 不捕获任何外部变量 [=] // 以值的形式捕获所有外部变量 [&amp;] // 以引用形式捕获所有外部变量 [x, &amp;y] // x 以传值形式捕获，y 以引用形式捕获 [=, &amp;z]// z 以引用形式捕获，其余变量以传值形式捕获 [&amp;, x] // x 以值的形式捕获，其余变量以引用形式捕获 对于[=]或[&amp;]的形式，lambda 表达式可以直接使用 this 指针 。但是，对于[]的形式，如果要使用 this 指针，必须显式传入： 对于下面的例子，[=]意味着，lambda 表达式以传值的形式捕获外部变量。C++ 11 标准说，如果以传值的形式捕获外部变量，那么，lambda 体不允许修改外部变量，对 f0 的任何修改都会引发编译错误。但是，注意在 lambda 表达式前声明了mutable关键字，这就允许了 lambda 表达式体修改 f0 的值。因此不会报错。但由于是传值的，虽然在 lambda 表达式中对 f0 有了修改，但由于是传值的，外部的 f0 依然不会被修改。 123float f0 = 1.0;std::cout &lt;&lt; [=](float f) mutable &#123; return f0 += std::abs(f); &#125; (-3.5);std::cout &lt;&lt; '\n' &lt;&lt; f0 &lt;&lt; '\n'; – 混合机制的实例如下（f0 通过引用被捕获，而其它变量，比如 f1 则是通过值被捕获）： 1234float f0 = 1.0f;float f1 = 10.0f;std::cout &lt;&lt; [=, &amp;f0](float a) &#123; return f0 += f1 + std::abs(a); &#125; (-3.5);std::cout &lt;&lt; '\n' &lt;&lt; f0 &lt;&lt; '\n'; C++引入Lambda的最主要原因:1）可以定义匿名函数；2）编译器会把其转成函数对象；为什么以前STL中的ptr_fun()这个函数对象不能用？（ptr_fun()就是把一个自然函数转成函数对象的）原因是，ptr_fun() 的局限是其接收的自然函数只能有1或2个参数。3）”闭包”，限制了别人的访问，更私有； 2.自动类型推导和 decltype在 C++03 中，声明对象的同时必须指明其类型，其实大多数情况下，声明对象的同时也会包括一个初始值，C++11 在这种情况下就能够让你声明对象时不再指定类型了。 1234auto x = 0; //0 是 int 类型，所以 x 也是 int 类型 auto c = 'a'; //char auto d = 0.5; //double auto national_debt = 14400000000000LL;//long long 这个特性在对象的类型很大很长的时候很有用，如： 123456 void func(const vector&lt;int&gt; &amp;vi) &#123; //vector&lt;int&gt;::const_iterator ci=vi.begin(); auto ci=vi.begin(); &#125; C++11 也提供了从对象或表达式中“俘获”类型的机制，新的操作符 decltype 可以从一个表达式中“俘获”其结果的类型并“返回”： 123const vector&lt;int&gt; vi; typedef decltype (vi.begin()) CIT; CIT another_const_iterator; 注意： auto作为函数返回值时，只能用于定义函数，不能用于声明函数 3.统一的初始化语法12345678910111213141516//括号内初始化std::string s("hello"); int m=int(); //default initialization //等号形式的std::string s="hello"; int x=5; //对于 POD 集合，又可以用大括号int arr[4]=&#123;0,1,2,3&#125;; struct tm today=&#123;0&#125;; //最后还有构造函数的成员初始化：struct S &#123; int x; S(): x(0) &#123;&#125; &#125;; C++11 就用大括号一统天下了!对于容器来说，终于可以摆脱 push_back() 调用了，C++11中可以直观地初始化容器了: 12345// C++11 container initializer vector vs&lt;string&gt;=&#123; "first", "second", "third"&#125;; map singers = &#123; &#123;"Lady Gaga", "+1 (212) 555-7890"&#125;, &#123;"Beyonce Knowles", "+1 (212) 555-0987"&#125;&#125;; 而类中的数据成员初始化也得到了支持： 123456class C &#123; int a=7; //C++11 only public: C(); &#125;; 4.deleted 函数和 defaulted 函数12345struct A &#123; A()=default; //C++11 virtual ~A()=default; //C++11 &#125;; =default; 指示编译器生成该函数的默认实现。这有两个好处：一是让程序员轻松了，少敲键盘，二是有更好的性能。与 defaulted 函数相对的就是 deleted 函数, 实现 non copy-able 防止对象拷贝，要想禁止拷贝，用 =deleted 声明一下两个关键的成员函数就可以了： 12345678910int func()=delete; //防止对象拷贝的实现struct NoCopy &#123; NoCopy &amp; operator =(const NoCopy &amp;) = delete; NoCopy(const NoCopy &amp;) = delete; &#125;; NoCopy a; NoCopy b(a); //编译错误，拷贝构造函数是 deleted 函数 5.nullptrnullptr 是一个新的 C++ 关键字，它是空指针常量，它是用来替代高风险的 NULL 宏和 0 字面量的。nullptr 是强类型的,所有跟指针有关的地方都可以用 nullptr，包括函数指针和成员指针： 123456789101112void f(int); //#1 void f(char *);//#2 //C++03 f(0); //调用的是哪个 f? //C++11 f(nullptr) //毫无疑问，调用的是 #2 const char *pc=str.c_str(); //data pointers if (pc != nullptr) cout &lt;&lt; pc &lt;&lt; endl; int (A::*pmf)()=nullptr; //指向成员函数的指针 void (*pmf)()=nullptr; //指向函数的指针 6.右值引用在 C++03 中的引用类型是只绑定左值的，C++11 引用一个新的引用类型叫右值引用类型，它是绑定到右值的，如临时对象或字面量。增加右值引用的主要原因是为了实现 move 语义。与传统的拷贝不同，move 的意思是目标对象“窃取”原对象的资源，并将源置于“空”状态。当拷贝一个对象时，其实代价昂贵且无必要，move 操作就可以替代它。如在 string 交换的时候，使用 move 意义就有巨大的性能提升，如下所示： 12345678910111213141516171819202122//原方案很慢，因为需要申请内存，然后拷贝字符；[cpp] view plain copyvoid naiveswap(string &amp;a, string &amp; b) &#123; string temp = a; a=b; b=temp; &#125; //使用move就只需要交换两个数据成员，无须申请、释放内存和拷贝字符数组；void moveswapstr(string&amp; empty, string &amp; filled) &#123; //pseudo code, but you get the idea size_t sz=empty.size(); const char *p= empty.data(); //move filled's resources to empty empty.setsize(filled.size()); empty.setdata(filled.data()); //filled becomes empty filled.setsize(sz); filled.setdata(p); &#125; 要实现支持 move 的类，需要声明 move 构造函数和 move 赋值操作符，如下： 12345class Movable &#123; Movable (Movable&amp;&amp;); //move constructor Movable&amp;&amp; operator=(Movable&amp;&amp;); //move assignment operator &#125;; C++11 的标准库线程库、新的智能指针类、]]></content>
      <tags>
        <tag>技术 编程语言 C++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker常用命令]]></title>
    <url>%2F2018%2F12%2F27%2Fdocker%2F</url>
    <content type="text"><![CDATA[docker是什么？docker是一个开源的容器引擎，它基于LCX容器技术，使用Go语言开发。源代码托管在Github上，并遵从Apache2.0协议。Docker采用C/S架构，其可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。 简单来说：Docker就是一种快速解决生产问题的一种技术手段。简单点：Docker就是对容器进行操作管理的工具 docker优缺点优点：多： 适用场景多快： 环境部署快、更新快好： 好多人在用省： 省钱省力省人工 缺点：太腻歪人： 依赖操作系统不善沟通： 依赖网络不善理财： 银行U盾等场景不能用 镜像命令搜索 ： docker search 【image_name】获取 ： docker pull 【image_name】查看 ： docker image 【image_name】docker image -a 列出本地的image（包括已删除的镜像记录）镜像重命名： docker tag [old_name]:[old_version] [new_name]:[new_verdion]删除镜像：docker rmi [image_id]导出镜像：（将已下载好的镜像，导出到本地） docker save -o [导出镜像名称] [本地镜像] 例：docker save -o nginx.tar nginx 导入镜像： docker load &lt; [image.tar_name] 容器命令查看容器： docker ps启动容器三种方式： 基于镜像新建一个容器并启动docker run &lt;参数，可选&gt; [docker_image] [执行命令]docker run 其实是两个命令的结合体docker create + docker start 将关闭的容器重新启动docker start [container_id] 守护进程方式启动(常用方式)docker run -d [image_name] command…例：docker run -d nginx 关闭容器： docker stop [container_id] 删除容器的三种方式：1.正常删除- - -删除已关闭的docker rm [container_id] 2.强制删除- - - 删除正在运行的docker rm -f [container_id] 3.强制批量删除- - - 删除全部容器docker rm -f $(docker ps -a -q) 进入容器三种方法：1.创建容器的同事并且进入容器docker run –name [container_name] -it [docker_image] /bin/bash 2.手工方式进入容器docker exec -it 容器id /bin/bash 3.生产方式进入容器 我们生产中常用的进入容器方法是使用脚本，脚本内容如下: 12345678#!/bin/bash# 定义进入仓库函数docker_in()&#123; NAME_ID=$1 PID=$(docker inspect --format &#123;&#123;.State.Pid&#125;&#125; $NAME_ID) nsenter --target $PID --mount --uts --ipc --net --pid&#125;docker_in $1]]></content>
      <tags>
        <tag>技术 容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO阻塞与非阻塞一篇就够了]]></title>
    <url>%2F2018%2F12%2F27%2Fio_sync%2F</url>
    <content type="text"><![CDATA[什么叫IOio通常是指计算机系统输入和输出的称呼，包括设备（键盘鼠标显示器）、总线、磁盘读写、内存等都称之为IO。 IO阻塞与非阻塞阻塞（block）：用户态进程切换至内核态进程（read，write，accept等API函数系统调用），用户态进程一直处于挂起状态，直至内核态返回，继续工作。 非阻塞（nonblock）:用户态进程切换至内核态进程（read，write，accept等API函数系统调用），内核态进程会立马返回数据或状态码给用户态进程，用户态进程无需处于挂起状态，一直处于忙碌状态。 同步与异步同步（synchronous）:一个服务进行数据请求时，服务方立马告知请求结果，若数据不满足，请求方会再次主动发送请求到服务方，直至请求方得到满意的回复。（期望的结果） 异步（asynchronous）：客户向服务方请求，服务方也会立马回复请求方，不同的是，客户请求方只留下一个回调函数，用来让服务方等待条件满足后，主动通知客户方最终结果。（此方式客户方只请求了一次服务方） 阻塞、非阻塞和同步异步是两个不同的概念。 同步与异步最大的差异是对待结果的返回方式不一样。]]></content>
      <tags>
        <tag>技术 linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2018%2F12%2F26%2Fthreadpool%2F</url>
    <content type="text"><![CDATA[为什么需要线程池在那些情况下我们会使用到多线程： 1.阻塞调用（阻塞IO调用、等待资源）2.耗时的计算（读写文件、复杂的计算）3.高密度任务（高并发低延时的网络IO请求）面临以上情况时都去临时创建线程会带来什么问题： 1.创建了太多的线程，系统资源就会被浪费，而且会浪费时间去创建和销毁线程。2.创建线程太慢，导致执行任务结果返回过慢。3.销毁线程太慢，可能会影响别的进程使用资源。所以：创建多个线程，放在池子里不销毁，要用的时候就把任务丢给池子里的线程去执行，这就是线程池。OK，问题来了任务由谁产生（生产者），如何丢给线程池的某个线程（消费者）？这个问题的回答需从以下几方面： 1） 生产者采用什么方式与消费者同步？2） 任务如何保存？3） 生产者之间的同步方式，消费者之间的同步方式？ 一下所有的代码设计适用于单生产者多消费者模式 条件变量结合互斥锁 + 任务队列设计如何： 代码如下： 123456789101112131415161718192021222324252627typedef struct queue_task&#123; void* (*run)(void *); void* argv;&#125;task_t;typedef struct queue&#123; int head; int tail; int size; int capcity; task_t* tasks;&#125; queue_t;typedef struct async_queue&#123; pthread_mutex_t mutex; pthread_cond_t cond; int waiting_threads; queue_t* queue; int quit; // 0 表示不退出 1 表示退出 /* 调试变量 */ long long tasked; // 已经处理完的任务数量&#125; async_queue_t; 取任务的代码设计如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344task_t* async_cond_queue_pop_head(async_queue_t* q, int timeout)&#123; task_t *task = NULL; struct timeval now; struct timespec outtime; pthread_mutex_lock(&amp;(q-&gt;mutex)); if (queue_is_empty(q-&gt;queue)) &#123; q-&gt;waiting_threads++; while (queue_is_empty(q-&gt;queue) &amp;&amp; (q-&gt;quit == 0)) &#123; gettimeofday(&amp;now, NULL); if (now.tv_usec + timeout &gt; 1000) &#123; outtime.tv_sec = now.tv_sec + 1; outtime.tv_nsec = ((now.tv_usec + timeout) % 1000) * 1000; &#125; else &#123; outtime.tv_sec = now.tv_sec; outtime.tv_nsec = (now.tv_usec + timeout) * 1000; &#125; pthread_cond_timedwait(&amp;(q-&gt;cond), &amp;(q-&gt;mutex), &amp;outtime); &#125; q-&gt;waiting_threads--; &#125; task = queue_pop_head(q-&gt;queue); /* 调试代码 */ if (task) &#123; q-&gt;tasked ++; static long long precision = 10; if ((q-&gt;tasked % precision ) == 0) &#123; time_t current_stm = get_current_timestamp(); precision *= 10; &#125; &#125; pthread_mutex_unlock(&amp;(q-&gt;mutex)); return task;&#125; 详情见：https://github.com/zhiyong0804/f-threadpool/blob/master/async_cond_queue.c 不足： 因为Mutex引起线程挂起和唤醒的操作，在IO密集型的服务器上不是特别高效（实测过）；条件变量必须和互斥锁相结合使用，使用起来较麻烦；条件变量不能像eventfd一样为I/O事件驱动。管道可以和I/O复用很好的融合，但是管道比eventfd多用了一个文件描述符，而且管道内核还得给其管理的缓冲区，eventfd则不需要，因此eventfd比起管道要高效。 eventfd + epoll队列的设计： 1234567891011typedef struct async_queue&#123; queue_t* queue; int quit; // 0 表示不退出 1 表示退出 int efd; //event fd, int epollfd; // epoll fd /* 调试变量 */ long long tasked; // 已经处理完的任务数量&#125; async_queue_t; 插入任务： 123456789101112131415161718192021222324BOOL async_eventfd_queue_push_tail(async_queue_t* q, task_t *task)&#123; unsigned long long i = 0xffffffff; if (!queue_is_full(q-&gt;queue)) &#123; queue_push_tail(q-&gt;queue, task); struct epoll_event ev; int efd = eventfd(0, EFD_CLOEXEC | EFD_NONBLOCK); if (efd == -1) printf("eventfd create: %s", strerror(errno)); ev.events = EPOLLIN ;// | EPOLLLT; ev.data.fd = efd; if (epoll_ctl(q-&gt;epollfd, EPOLL_CTL_ADD, efd, &amp;ev) == -1) &#123; return NULL; &#125; write(efd, &amp;i, sizeof (i)); return TRUE; &#125; return FALSE;&#125; 取任务： 1234567891011121314151617181920212223242526272829303132task_t* async_eventfd_queue_pop_head(async_queue_t* q, int timeout)&#123; unsigned long long i = 0; struct epoll_event events[MAX_EVENTS]; int nfds = epoll_wait(q-&gt;epollfd, events, MAX_EVENTS, -1); if (nfds == -1) &#123; return NULL; &#125; else &#123; read(events[0].data.fd, &amp;i, sizeof (i)); close(events[0].data.fd); // NOTE: need to close here task_t* task = queue_pop_head(q-&gt;queue); /* 调试代码 */ if (task) &#123; q-&gt;tasked ++; static long long precision = 10; if ((q-&gt;tasked % precision ) == 0) &#123; time_t current_stm = get_current_timestamp(); printf("%d tasks cost : %d\n", precision, current_stm - start_stm); precision *= 10; &#125; &#125; return task; &#125; return NULL;&#125; 因为eventfd每次写数据后，只会唤醒一个epoll_wait所在的线程，so，确保了同一时刻仅有一个线程取任务。代码详情：https://github.com/zhiyong0804/f-threadpool/blob/master/async_eventfd_queue.c 不足：上面两种方案，所有的线程共用同一个队列，所以消费者线程之间取任务时需要做同步，生产者和消费者也需要做同步。用一个形象的图可以表示如下： eventfd + epoll + 多队列的设计设计思想如下图： 代码详情见：https://github.com/zhiyong0804/StreamingServerOh my god, huge project, where can i find thre thread pool source. 说来话长，这个代码是EasyDarwin的源码，但是因为某种原因，EasyDarwin的源码不再共享，取而代之的打赏的二维码，so， 我把他们的源码做了局部的修改，然后重新提交，且命名为StreamingServer，里面的设计是采用条件变量做同步的，但是多队列的思想是可以沿袭的，打算加班用eventfd实现。 这样一种设计是不是让我们能够想到下面这幅图呢？ 之前所有的道路遇到十字路口时（共享了资源），只能使用信号灯去同步汽车的行驶，现如今，把共享资源fuck掉了，用立交桥，爽吧！！！？ 并行编程是很难的，可以参考以下这篇论文: 并发编程的11个问题英文版：http://www.it610.com/article/4462577.htm并发编程的11个问题中文版：https://blog.csdn.net/mergerly/article/details/39028861我也并不聪明，可是当我2年前接触到ZeroMQ这个项目时，我特别惊叹于Pieter Hintjens的一些观点，“真正的并发就是不共享资源” so，方案四的设计 Lock-free当我们在第三种方案上，增加了多队列，即每线程每队列时，实际上我们的队列设计变成了一个单生产者单消费者共享的队列，但是这个队列的写指针（tail）仅会被生产者使用，读指针（head）仅会被消费者使用，实际上没有共享任何资源，当然queue_t的size变量，我正在重构把它拿掉。 OK，那么在这种设计下，消费者线程如何“等待”如何“取”任务？ 实际上，上面的三种方案对于消费者线程都是被动等待通知，收到通知则去取任务，实际上，我们完全可以设计成“轮询”的方案，就是不停地看自己的任务队列里是否有任务，没有就循环一次，中间当然可以加上sched_yield操作，让其它的线程能够得到调度。 线程池的尺寸设计多大合适？CPU密集型的：thread size = N + 1;IO密集型的：thread size = 2*N + 1; 当然这不是绝对的，所以在mariadb的线程池是可以动态调整这个尺寸的。 ——————————————全文完—————————————————–]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mutex的实现原理]]></title>
    <url>%2F2018%2F12%2F26%2Fmutex%2F</url>
    <content type="text"><![CDATA[互斥锁主要用于实现内核中的互斥访问功能。内核互斥锁是在原子 API 之上实现的，但这对于内核用户是不可见的。对它的访问必须遵循一些规则：同一时间只能有一个任务持有互斥锁，而且只有这个任务可以对互斥锁进行解锁。互斥锁不能进行递归锁定或解锁。一个互斥锁对象必须通过其API初始化，而不能使用memset或复制初始化。一个任务在持有互斥锁的时候是不能结束的。互斥锁所使用的内存区域是不能被释放的。使用中的互斥锁是不能被重新初始化的。并且互斥锁不能用于中断上下文。但是互斥锁比当前的内核信号量选项更快，并且更加紧凑，因此如果它们满足您的需求，那么它们将是您明智的选择。 定义123456789101112131415164.15 kernelinclude/linux/mutex.hstruct mutex &#123; atomic_long_t owner; spinlock_t wait_lock;#ifdef CONFIG_MUTEX_SPIN_ON_OWNER struct optimistic_spin_queue osq; /* Spinner MCS lock */#endif struct list_head wait_list;#ifdef CONFIG_DEBUG_MUTEXES void *magic;#endif#ifdef CONFIG_DEBUG_LOCK_ALLOC struct lockdep_map dep_map;#endif&#125;; 1.owner锁的持有者, 如果没有task持有则为0，否则是获取到锁的pid。2.wait_lock自旋锁，内核用来保护代码执行区的。3.wait_list等待队列，是一个链表，如果task没有获取owner == 0，则把task加入到这个等待队列，并且将进程设置为TASK_UNINTERRUPTIBLE状态，直到被wakeup调用唤醒执行。 mutex_lock123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213// linux/kener/locking/mutex.c:252/** * mutex_lock - acquire the mutex * @lock: the mutex to be acquired * * Lock the mutex exclusively for this task. If the mutex is not * available right now, it will sleep until it can get it. * * The mutex must later on be released by the same task that * acquired it. Recursive locking is not allowed. The task * may not exit without first unlocking the mutex. Also, kernel * memory where the mutex resides must not be freed with * the mutex still locked. The mutex must first be initialized * (or statically defined) before it can be locked. memset()-ing * the mutex to 0 is not allowed. * * (The CONFIG_DEBUG_MUTEXES .config option turns on debugging * checks that will enforce the restrictions and will also do * deadlock debugging) * * This function is similar to (but not equivalent to) down(). */void __sched mutex_lock(struct mutex *lock)&#123; might_sleep(); if (!__mutex_trylock_fast(lock)) __mutex_lock_slowpath(lock);&#125;static __always_inline bool __mutex_trylock_fast(struct mutex *lock)&#123; unsigned long curr = (unsigned long)current; unsigned long zero = 0UL; if (atomic_long_try_cmpxchg_acquire(&amp;lock-&gt;owner, &amp;zero, curr)) return true; return false;&#125;/* * Lock a mutex (possibly interruptible), slowpath: */static __always_inline int __sched__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass, struct lockdep_map *nest_lock, unsigned long ip, struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)&#123; struct mutex_waiter waiter; bool first = false; struct ww_mutex *ww; int ret; might_sleep(); ww = container_of(lock, struct ww_mutex, base); if (use_ww_ctx &amp;&amp; ww_ctx) &#123; if (unlikely(ww_ctx == READ_ONCE(ww-&gt;ctx))) return -EALREADY; /* * Reset the wounded flag after a kill. No other process can * race and wound us here since they can't have a valid owner * pointer if we don't have any locks held. */ if (ww_ctx-&gt;acquired == 0) ww_ctx-&gt;wounded = 0; &#125; preempt_disable(); mutex_acquire_nest(&amp;lock-&gt;dep_map, subclass, 0, nest_lock, ip); if (__mutex_trylock(lock) || mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) &#123; /* got the lock, yay! */ lock_acquired(&amp;lock-&gt;dep_map, ip); if (use_ww_ctx &amp;&amp; ww_ctx) ww_mutex_set_context_fastpath(ww, ww_ctx); preempt_enable(); return 0; &#125; spin_lock(&amp;lock-&gt;wait_lock); /* * After waiting to acquire the wait_lock, try again. */ if (__mutex_trylock(lock)) &#123; if (use_ww_ctx &amp;&amp; ww_ctx) __ww_mutex_check_waiters(lock, ww_ctx); goto skip_wait; &#125; debug_mutex_lock_common(lock, &amp;waiter); lock_contended(&amp;lock-&gt;dep_map, ip); if (!use_ww_ctx) &#123; /* add waiting tasks to the end of the waitqueue (FIFO): */ __mutex_add_waiter(lock, &amp;waiter, &amp;lock-&gt;wait_list);#ifdef CONFIG_DEBUG_MUTEXES waiter.ww_ctx = MUTEX_POISON_WW_CTX;#endif &#125; else &#123; /* * Add in stamp order, waking up waiters that must kill * themselves. */ ret = __ww_mutex_add_waiter(&amp;waiter, lock, ww_ctx); if (ret) goto err_early_kill; waiter.ww_ctx = ww_ctx; &#125; waiter.task = current; set_current_state(state); for (;;) &#123; /* * Once we hold wait_lock, we're serialized against * mutex_unlock() handing the lock off to us, do a trylock * before testing the error conditions to make sure we pick up * the handoff. */ if (__mutex_trylock(lock)) goto acquired; /* * Check for signals and kill conditions while holding * wait_lock. This ensures the lock cancellation is ordered * against mutex_unlock() and wake-ups do not go missing. */ if (unlikely(signal_pending_state(state, current))) &#123; ret = -EINTR; goto err; &#125; if (use_ww_ctx &amp;&amp; ww_ctx) &#123; ret = __ww_mutex_check_kill(lock, &amp;waiter, ww_ctx); if (ret) goto err; &#125; spin_unlock(&amp;lock-&gt;wait_lock); schedule_preempt_disabled(); /* * ww_mutex needs to always recheck its position since its waiter * list is not FIFO ordered. */ if ((use_ww_ctx &amp;&amp; ww_ctx) || !first) &#123; first = __mutex_waiter_is_first(lock, &amp;waiter); if (first) __mutex_set_flag(lock, MUTEX_FLAG_HANDOFF); &#125; set_current_state(state); /* * Here we order against unlock; we must either see it change * state back to RUNNING and fall through the next schedule(), * or we must see its unlock and acquire. */ if (__mutex_trylock(lock) || (first &amp;&amp; mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &amp;waiter))) break; spin_lock(&amp;lock-&gt;wait_lock); &#125; spin_lock(&amp;lock-&gt;wait_lock);acquired: __set_current_state(TASK_RUNNING); if (use_ww_ctx &amp;&amp; ww_ctx) &#123; /* * Wound-Wait; we stole the lock (!first_waiter), check the * waiters as anyone might want to wound us. */ if (!ww_ctx-&gt;is_wait_die &amp;&amp; !__mutex_waiter_is_first(lock, &amp;waiter)) __ww_mutex_check_waiters(lock, ww_ctx); &#125; mutex_remove_waiter(lock, &amp;waiter, current); if (likely(list_empty(&amp;lock-&gt;wait_list))) __mutex_clear_flag(lock, MUTEX_FLAGS); debug_mutex_free_waiter(&amp;waiter);skip_wait: /* got the lock - cleanup and rejoice! */ lock_acquired(&amp;lock-&gt;dep_map, ip); if (use_ww_ctx &amp;&amp; ww_ctx) ww_mutex_lock_acquired(ww, ww_ctx); spin_unlock(&amp;lock-&gt;wait_lock); preempt_enable(); return 0;err: __set_current_state(TASK_RUNNING); mutex_remove_waiter(lock, &amp;waiter, current);err_early_kill: spin_unlock(&amp;lock-&gt;wait_lock); debug_mutex_free_waiter(&amp;waiter); mutex_release(&amp;lock-&gt;dep_map, 1, ip); preempt_enable(); return ret;&#125; 从以上代码可以看出，如果task获取不到锁，则先把自己加入到等待队列，并且设置进程状态为TASK_UNINTERRUPTIBLE，让出CPU的执行。 mutex_unlock1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * mutex_unlock - release the mutex * @lock: the mutex to be released * * Unlock a mutex that has been locked by this task previously. * * This function must not be used in interrupt context. Unlocking * of a not locked mutex is not allowed. * * This function is similar to (but not equivalent to) up(). */void __sched mutex_unlock(struct mutex *lock)&#123;#ifndef CONFIG_DEBUG_LOCK_ALLOC if (__mutex_unlock_fast(lock)) return;#endif __mutex_unlock_slowpath(lock, _RET_IP_);&#125;/* * Release the lock, slowpath: */static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)&#123; struct task_struct *next = NULL; DEFINE_WAKE_Q(wake_q); unsigned long owner; mutex_release(&amp;lock-&gt;dep_map, 1, ip); /* * Release the lock before (potentially) taking the spinlock such that * other contenders can get on with things ASAP. * * Except when HANDOFF, in that case we must not clear the owner field, * but instead set it to the top waiter. */ owner = atomic_long_read(&amp;lock-&gt;owner); for (;;) &#123; unsigned long old;#ifdef CONFIG_DEBUG_MUTEXES DEBUG_LOCKS_WARN_ON(__owner_task(owner) != current); DEBUG_LOCKS_WARN_ON(owner &amp; MUTEX_FLAG_PICKUP);#endif if (owner &amp; MUTEX_FLAG_HANDOFF) break; old = atomic_long_cmpxchg_release(&amp;lock-&gt;owner, owner, __owner_flags(owner)); if (old == owner) &#123; if (owner &amp; MUTEX_FLAG_WAITERS) break; return; &#125; owner = old; &#125; spin_lock(&amp;lock-&gt;wait_lock); debug_mutex_unlock(lock); if (!list_empty(&amp;lock-&gt;wait_list)) &#123; /* get the first entry from the wait-list: */ struct mutex_waiter *waiter = list_first_entry(&amp;lock-&gt;wait_list, struct mutex_waiter, list); next = waiter-&gt;task; debug_mutex_wake_waiter(lock, waiter); wake_q_add(&amp;wake_q, next); &#125; if (owner &amp; MUTEX_FLAG_HANDOFF) __mutex_handoff(lock, next); spin_unlock(&amp;lock-&gt;wait_lock); wake_up_q(&amp;wake_q);&#125; 释放锁时，先检查ower是否是自己，如果是的，则从等待队列（wait_list）拿取第一个task，并且调用wake_up_q去唤醒task，task恢复执行。 ——————————————全文完—————————————————–]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协程]]></title>
    <url>%2F2018%2F12%2F26%2Fxiecheng%2F</url>
    <content type="text"><![CDATA[协程，英文（coroutines）,是一种比线程更加轻量级的存在。 一个进程可以拥有多个线程，一个线程也可以拥有多个协程。 最重要的是，协程不是被操作系统内核所管理（内核调用），而完全是由用户态程序所控制（用户态执行）。 这样带来的好处就是性能得到了很大的提升，不像进程线程切换带来的消耗资源，cpu的调度。 协程的开销远远小于线程的开销。 协程并不想线程需要锁机制，协程中控制共享资源不加锁，只需要判断状态就好，所以执行效率比多线程高的多。 因为协程是一个线程执行，那怎么利用多核CPU呢？ 最简单的方法就是多进程+协程，既充分利用多核，又充分发挥协程的高效率。 ==协程允许我们写同步代码的逻辑，却做着异步的事，避免回调嵌套，使得代码逻辑清晰（协程是追求极限性能和优美的代码结构产物）== 参考手册 : 协程详细介绍]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <url>%2F2018%2F12%2F26%2Fgit%2F</url>
    <content type="text"><![CDATA[1.git与SVN的区别git是分布式版本控制系统。必须客户端连接上服务端才能正常工作。svn是集中式版本控制系统。每台机器就是一个单独运行的库，方便高效便捷的开发。 2.git常用命令git config -global ; 配置环境信息git init ；将目录变成git管理的仓库，初始化仓库git add ;提交到暂存区git commit; 提交到本地仓git status ;查看仓库是否有文件未提交git diff 文件名；比较文件git reset -hard HEAD~100;回到前100个版本git reset -hard(版本号)；回到指定的版本号git reflog；取得版本号 git checkout -b ;创建并且换到分支git branch dev ；创建分支git checkout dev；切换分支git merge dev; 将dev分支上的内容合并到主支master上git branch -d name;删除分支 参考手册 : git详细介绍]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua脚本式编程]]></title>
    <url>%2F2018%2F12%2F26%2Flua%2F</url>
    <content type="text"><![CDATA[1.基本语法单行注释：–多行注释：–[[ 内容–]] lua最好不要使用下划线加大字母的标识符，因为lua的保留字是这样的。lua不允许使用特殊字符如@$%来定义标志符。 默认情况下，变量总是认为全局。删除全局变量，只需要将变量赋值nil . lua的数据类型：nil 、boolean、number、string、userdata、function、thread和table。 nil作为比较时应该加上双引号，例如 12type(x) == &quot;nil&quot; boolean类型只有两个可选值：true 和 falselua把false和nil看作是“假”，其他都为真。 number（数字）：lua只有一种number类型，double双精度类型，默认类型可以修改luaconf.h里面的定义。 string（字符串）：由一对双引号或单引号来表示，也可以用2个方括号“[[ ]]”来表示“一块”字符串。 对一个数字字符串上进行算术操作时，lua会尝试将这个数字字符串转换成一个数字。 12print(“2”+6) 8.0print("2"+"6") 8.0 字符串连接使用的是 . .如： 12print("a" .. "b") abprint(157 .. 428) 157428 #计算字符串的长度。 123len ="www.runoob.com"print(#len) 14print(#"www.runoob.com") 14 2.宿主语言C/C++==虚拟栈== 无论何时lua调用C，被调用的函数都得到一个新的栈，这个栈独立于C函数本身的栈，也独立于之前的栈。 方便起见，所有正对栈的API查询操作都不严格遵守栈的操作规则。而是可以用一个索引来指向栈上的任何元素： ==正的索引指的是栈上的绝对位置（从1开始），负的索引指从栈顶开始的偏移量。== Lua_checkstack:扩大可用堆栈的尺寸LUA_MINSTACK一般被定义为20。 压入栈的数据类型包括数值、字符串、指针、table、闭包。 Lua_pushcclosure(L,func,0)；创建并压入一个闭包Lua_createtable(L,0,0)；新建并压入一个表Lua_pushnumber(L,343)；压入一个数字Lua_pushstring(L,”Nystr”)；压入一个字符串 Lua中，number、boolean、nil、lightuserdata四种类型的值是直接存在栈上元素里和垃圾回收无关。Lua中，string、table、closure、userdata、thread存在栈上元素里的只是指针，他们都会在生命周期结束后被垃圾回收。 Lua_push族函数都有“创建一个类型的值并压入”的语义。Lua value -&gt; C value时，是通过Lua_to族api实现的。 123456取表中元素 void lua_getfield(lua_state *L,int index,const char *K)操作： arr = stack[index] stack.push(arr[K]) 取表中键为K的元素，这里的表是由index指向的栈上的一个表。 栈高度+1，栈顶元素是（stack[index]）[K]。]]></content>
      <tags>
        <tag>技术,编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP通讯知识]]></title>
    <url>%2F2018%2F11%2F25%2FTCP-IP%E9%80%9A%E8%AE%AF%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"></content>
      <categories>
        <category>TCP</category>
      </categories>
      <tags>
        <tag>TCP网络通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test_md]]></title>
    <url>%2F2018%2F11%2F23%2Ftest-md%2F</url>
    <content type="text"></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F11%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[notshow: trueWelcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hexo查询</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
