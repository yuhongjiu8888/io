<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2020%2F03%2F10%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[区块链研究 加拿大-jasper https://www.jinse.com/blockchain/446071.html 新加坡-ubin https://www.jinse.com/news/blockchain/47362.html ​ https://www.jinse.com/blockchain/555141.html 泰国-Inthanonhttps://www.chainnews.com/articles/832267900915.htm]]></content>
  </entry>
  <entry>
    <title><![CDATA[malloc、calloc、realloc的区别]]></title>
    <url>%2F2019%2F01%2F24%2Fmalloc%2F</url>
    <content type="text"><![CDATA[C语言跟内存申请相关的函数主要有 alloca、calloc、malloc、free、realloc等. alloca是向栈申请内存,因此无需释放. malloc分配的内存是位于堆中的,并且没有初始化内存的内容,因此基本上malloc之后,调用函数memset来初始化这部分的内存空间. calloc则将初始化这部分的内存,设置为0. realloc则对malloc申请的内存进行大小的调整. 申请的内存最终需要通过函数free来释放. 当程序运行过程中malloc了,但是没有free的话,会造成内存泄漏.一部分的内存没有被使用,但是由于没有free,因此系统认为这部分内存还在使用,造成不断的向系统申请内存,使得系统可用内存不断减少.但是内存泄漏仅仅指程序在运行时,程序退出时,OS将回收所有的资源.因此,适当的重起一下程序,有时候还是有点作用.【attention】 三个函数的申明分别是: void malloc(unsigned size); void realloc(void ptr, unsigned newsize); void calloc(size_t numElements, size_t sizeOfElement); 都在stdlib.h函数库内，它们的返回值都是请求系统分配的地址,如果请求失败就返回NULL. (1)函数malloc() 在内存的动态存储区中分配一块长度为size字节的连续区域，参数size为需要内存空间的长度，返回该区域的首地址. (2)函数calloc() 与malloc相似,参数sizeOfElement为申请地址的单位元素长度,numElements为元素个数，即在内存中申请numElementssizeOfElement字节大小的连续地址空间. (3)函数realloc() 给一个已经分配了地址的指针重新分配空间,参数ptr为原有的空间地址,newsize是重新申请的地址长度. 区别: (1)函数malloc不能初始化所分配的内存空间,而函数calloc能.如果由malloc()函数分配的内存空间原来没有被使用过，则其中的每一位可能都是0;反之, 如果这部分内存曾经被分配过,则其中可能遗留有各种各样的数据.也就是说，使用malloc()函数的程序开始时(内存空间还没有被重新分配)能正常进行,但经过一段时间(内存空间还已经被重新分配)可能会出现问题. (2)函数calloc() 会将所分配的内存空间中的每一位都初始化为零,也就是说,如果你是为字符类型或整数类型的元素分配内存,那么这些元素将保证会被初始化为0;如果你是为指针类型的元素分配内存,那么这些元素通常会被初始化为空指针;如果你为实型数据分配内存,则这些元素会被初始化为浮点型的零. (3)函数malloc向系统申请分配指定size个字节的内存空间.返回类型是 void类型.void表示未确定类型的指针.C,C++规定，void 类型可以强制转换为任何其它类型的指针. (4)realloc可以对给定的指针所指的空间进行扩大或者缩小，无论是扩张或是缩小，原有内存的中内容将保持不变.当然，对于缩小，则被缩小的那一部分的内容会丢失.realloc并不保证调整后的内存空间和原来的内存空间保持同一内存地址.相反，realloc返回的指针很可能指向一个新的地址. (5)realloc是从堆上分配内存的.当扩大一块内存空间时，realloc()试图直接从堆上现存的数据后面的那些字节中获得附加的字节，如果能够满足，自然天下太平；如果数据后面的字节不够，问题就出来了，那么就使用堆上第一个有足够大小的自由块，现存的数据然后就被拷贝至新的位置，而老块则放回到堆上.这句话传递的一个重要的信息就是数据可能被移动. reference]]></content>
      <tags>
        <tag>技术 编程语言 C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C时间戳]]></title>
    <url>%2F2019%2F01%2F12%2FC_time%2F</url>
    <content type="text"><![CDATA[clock()、time()、clock_gettime()和gettimeofday()函数的用法和区别1.精确度比较: 以下是各种精确度的类型转换:1秒=1000毫秒(ms), 1毫秒=1/1000秒(s)；1秒=1000000 微秒(μs), 1微秒=1/1000000秒(s)；1秒=1000000000 纳秒(ns),1纳秒=1/1000000000秒(s)； clock()函数的精确度是10毫秒(ms)times()函数的精确度是10毫秒(ms)gettimofday()函数的精确度是微秒(μs)clock_gettime()函数的计量单位为十亿分之一，也就是纳秒(ns) 详情]]></content>
      <tags>
        <tag>技术 C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL常用API]]></title>
    <url>%2F2019%2F01%2F04%2Fstl%2F</url>
    <content type="text"><![CDATA[序列容器常用容器：array、vector、deque、list、queue、stack要求：序列的元素必须是严格的线性顺序排序。因此序列中的元素具有确定的顺序，可以执行将值插入到特定位置、删除特定区间等操作。 array具体语法参考：http://www.cplusplus.com/reference/array/array/ vector具体语法参考：http://www.cplusplus.com/reference/vector/vector/ deque具体语法参考：http://www.cplusplus.com/reference/deque/deque/ list具体语法参考：http://www.cplusplus.com/reference/list/list/ queue（适配器）具体语法参考：http://www.cplusplus.com/reference/queue/queue/ stack(适配器)具体语法参考：http://www.cplusplus.com/reference/stack/stack/ C/C++STL常用容器用法总结：https://blog.csdn.net/weixin_41162823/article/details/79759081 关联容器关联容器与序列容器有着根本性的不同，序列容器的元素是按照在容器中的位置来顺序保存和访问的，而关联容器的元素是按关键元素来保存和访问的。关联容器支持高效的关键字查找与访问。两个主要的关联容器类型是map与set。 1.set1.1 简介：set里面每个元素只存有一个key，它支持高效的关键字查询操作。set对应数学中的“集合”。 具体语法参考：http://www.cplusplus.com/reference/set/set/ 1.2 特点： 储存同一类型的数据元素（这点和vector、queue等其他容器相同）每个元素的值都唯一（没有重复的元素）根据元素的值自动排列大小（有序性）无法直接修改元素高效的插入删除操作1.3 声明：set a set a={0,1,6,2,3};for(auto it = a.begin();it != a.end();it++) cout &lt;&lt; *it;//输出012361.4 常用函数 以下设 set a,其中a是T类型的set容器。 表达式 返回类型 说明 a.begin() 返回指向第一个元素的迭代器 a.end() 返回指向超尾的迭代器 a.clear() 清空容器a a.empty() 判断容器是否为空 a.size() 返回当前容器元素个数 a.count(x) 返回容器a中元素x的个数 1.6 插入元素： a.insert(x) :其中a为set型容器，x为T型变量 set a={0,1,2,9}; a.insert(6); for(auto it = a.begin();it != a.end();it++) cout &lt;&lt; it;//输出01269a.insert(first,second):其中first为指向区间左侧的迭代器，second为指向右侧的迭代器。作用是将first到second区间内元素插入到a（左闭右开）。set a = {0,1,2,9};set b = {3,4,5};auto first = b.begin();auto second = b.end();a.insert(first,second);for(auto it = a.begin();it != a.end();it++) cout &lt;&lt; it;插入元素会自动插入到合适的位置，使整个集合有序 1.7 删除元素： a.erase(x)：删除建值为x的元素a.erase(first,second)：删除first到second区间内的元素（左闭右开）a.erase(iterator):删除迭代器指向的元素set中的删除操作是不进行任何的错误检查的，比如定位器的是否合法等等，所以用的时候自己一定要注意。1.8 lower_bound 和 upper_bound 迭代器： lower_bound（x1）:返回第一个不小于键参数x1的元素的迭代器upper_bound（x2）:返回最后一个大于键参数x2的元素的迭代器由以上俩个函数，可以得到一个目标区间，即包含集合中从’x1’到’x2’的所有元素 #include #include #includeusing namespace std;int main(){ set a = {0,1,2,5,9}; auto it2 = a.lower_bound(2);//返回指向第一个大于等于x的元素的迭代器 auto it = a.upper_bound(2);//返回指向第一个大于x的元素的迭代器 cout &lt;&lt; it2 &lt;&lt; endl;//输出为2 cout &lt;&lt; it &lt;&lt; endl;//输出为5 return 0;}1.9 set_union() 与 set_intersection() set_union():对集合取并集 set_union()函数接受5个迭代器参数。前两个迭代器定义了第一个集合的区间，接下来的俩个迭代器定义了第二个集合的区间，最后一个迭代器是输出迭代器，指出将结果集合复制到什么位置。例如：要将A与B的集合复制到C中，可以这样写： #include #include #includeusing namespace std;int main(){ set A = {1,2,3}, B= {2,4,5},C; set_union(A.begin(),A.end(),B.begin(),B.end(), insert_iterator&lt;set &gt;(C,C.begin())); for(auto it = C.begin();it != C.end();it++) cout &lt;&lt; *it &lt;&lt;” “; return 0;}注意： 其中第五个参数不能写C.begin(),原因有两个：首先，关联集合将建看作常量，所以C.begin()返回的迭代器是常量迭代器，不能作为输出迭代器(详情请参考迭代器相关概念)。其次，与copy()相同，set_union()将覆盖容器中已有的数据，并且要求容器用足够的空间容纳新信息，而C不满足，因为它是空的。 解决方法：可以创建一个匿名的insert_iterator,将信息复制给C。如上述代码所为。另一种方法如下： set_union(A.begin(),A.end(),B.begin(),B.end(), inserter(C,C.begin()));//调用inserterset_intersection():对集合取交集，它的接口与set_union()相同。 附：使用set_union()和set_intersection()还有另一种技巧。由于需要五个迭代器，看起来会很累赘和麻烦，如果多次使用会增加出错的几率，所以我们可以试试用宏定义的方法来简化代码。如下： #include #include #includeusing namespace std; #define ALL(x) x.begin(),x.end() #define INS(x) inserter(x,x.begin())int main(){ set A = {1,2,3}, B= {2,4,5},C; set_union(ALL(A),ALL(B),INS(C)); for(auto it = C.begin();it != C.end();it++) cout &lt;&lt; *it &lt;&lt;” “; return 0;}其中使用到了宏定义。1.10 set的几个问题： （1）为何map和set的插入删除效率比用其他序列容器高？ 因为对于关联容器来说，不需要做内存拷贝和内存移动。set容器内所有元素都是以节点的方式来存储，其节点结构和链表差不多，指向父节点和子节点。因此插入的时候只需要稍做变换，把节点的指针指向新的节点就可以了。删除的时候类似，稍做变换后把指向删除节点的指针指向其他节点也OK了。这里的一切操作就是指针换来换去，和内存移动没有关系。 （2）为何每次insert之后，以前保存的iterator不会失效？ iterator这里就相当于指向节点的指针，内存没有变，指向内存的指针怎么会失效呢(当然被删除的那个元素本身已经失效了)。相对于vector来说，每一次删除和插入，指针都有可能失效，调用push_back在尾部插入也是如此。因为为了保证内部数据的连续存放，iterator指向的那块内存在删除和插入过程中可能已经被其他内存覆盖或者内存已经被释放了。即使时push_back的时候，容器内部空间可能不够，需要一块新的更大的内存，只有把以前的内存释放，申请新的更大的内存，复制已有的数据元素到新的内存，最后把需要插入的元素放到最后，那么以前的内存指针自然就不可用了。特别时在和find等算法在一起使用的时候，牢记这个原则：不要使用过期的iterator。 （3）当数据元素增多时，set的插入和搜索速度变化如何？ 如果你知道log2的关系你应该就彻底了解这个答案。在set中查找是使用二分查找，也就是说，如果有16个元素，最多需要比较4次就能找到结果，有32个元素，最多比较5次。那么有10000个呢？最多比较的次数为log10000，最多为14次，如果是20000个元素呢？最多不过15次。看见了吧，当数据量增大一倍的时候，搜索次数只不过多了1次，多了1/14的搜索时间而已。你明白这个道理后，就可以安心往里面放入元素了。 2.map2.1 简介：如果说set对应数学中的“集合”，那么map对应的就是“映射”。map是一种key-value型容器，其中key是关键字，起到索引作用，而value就是其对应的值。与set不同的是它支持下标访问。头文件是 具体语法参考：http://www.cplusplus.com/reference/map/map/ 2.2 特点： 增加和删除节点对迭代器的影响很小(高效的插入与删除)快速的查找（同set）自动建立key-value的对应，key和value可以是任何你需要的类型可以根据key修改value的记录支持下标[]操作2.3 声明：map&lt;T1,T2&gt; m 其中T1是key类型，T2是value类型，m就是一个T1-T2的key-value。 map&lt;string,int&gt; m;//声明一个key为string，value为int的map型容器下述代码更清楚的解释了map容器的特点： #include #includeusing namespace std;int main(){ map&lt;string,int&gt; m; m[“abc”] = 5; m[“cdf”] = 6; m[“b”] = 1; for(auto it = m.begin();it != m.end();it++) cout &lt;&lt; it-&gt;first &lt;&lt;” “ &lt;&lt; it-&gt;second &lt;&lt; endl; return 0;}在上述代码中，m容器被按照key的字典序升序排列了，而且我们可以通过将key当作索引来获取value的值。（同时这也是一种插入方法） 2.4 插入元素： 使用insert()函数插入pair类型的元素使用下标操作向map容器中插入元素map&lt;string,int&gt; m; m.insert(make_pair(“b”,6));//insert插入 m[“a”] = 5;//使用下标插入2.5 删除元素： erase(key):删除键为key的元素erase(it):删除迭代器it所指向的元素 #include #includeusing namespace std;int main(){ map&lt;string,int&gt; m; m.insert(make_pair(“b”,6)); m[“a”] = 5; m[“c”] = 5; m[“d”] = 5; m[“e”] = 5; m.erase(&quot;d&quot;); auto pr = m.begin(); m.erase(pr); for(auto it = m.begin();it != m.end();it++) cout &lt;&lt; it-&gt;first &lt;&lt;&quot; &quot; &lt;&lt; it-&gt;second &lt;&lt; endl; return 0; }2.6 map容器的遍历： 使用迭代器遍历（代码如上）注：使用迭代器遍历map容器，其中每一个元素可以看成是pair类型的，访问第一个位置的key值可以用it-&gt;first访问，第二个位置value的值可以用it-&gt;second访问，其中it是指向该元素的迭代器。2.7 常用函数： 下表中m为map类型的容器，it为和m同类型的迭代器，key表示该类型的一个键。 表达式 返回类型 说明 m.Count(key) 返回map中key出现的次数（0或1） m.find(key) 迭代器 返回指向key位置的迭代器.若无则返回m.end() m.insert(make_pair( ) ) 插入一个元素(必须以pair形式插入) m.erase(it) 删除迭代器it所指向的元素 m.erase(key) 删除键值为key的元素 m.size() 返回m中元素的个数 m.clear() 清空m容器 m.empty() bool 判断容器是否为空。空则返回true m.lower_bound(key) 迭代器 返回指向第一个键值不小于key的元素的迭代器 m.upper_bound(key) 迭代器 返回指向第一个键值大于key的元素的迭代器]]></content>
      <tags>
        <tag>技术 技术 编程语言 C++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL远程连接问题]]></title>
    <url>%2F2019%2F01%2F04%2Fmysql_1%2F</url>
    <content type="text"><![CDATA[如何让MySQL可以远程连接1.本地防火墙是否关闭 ufw status; 2.mysql配置文件my.cnf 注释掉 #bind 127.0.0.1 绑定本地地址 3.MySQL数据库user远程权限 grant all privileges on . to ‘root‘@’%’ identified by ‘123456’ with grant option;flush privileges;]]></content>
      <tags>
        <tag>mysql 数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11新特性]]></title>
    <url>%2F2018%2F12%2F27%2Fc%2B%2B11featrues%2F</url>
    <content type="text"><![CDATA[1.Lambda 表达式Lambda 表达式就是用于创建匿名函数的。为什么说 lambda 表达式如此激动人心呢？举一个例子。标准 C++ 库中有一个常用算法的库，其中提供了很多算法函数，比如 sort() 和 find()。这些函数通常需要提供一个“谓词函数 predicate function”。所谓谓词函数，就是进行一个操作用的临时函数。比如 find() 需要一个谓词，用于查找元素满足的条件；能够满足谓词函数的元素才会被查找出来。这样的谓词函数，使用临时的匿名函数，既可以减少函数数量，又会让代码变得清晰易读。 1[capture](parameters)-&gt;return-type &#123;body&#125; 最简单的例子如下： 123456789#include &lt;algorithm&gt;#include &lt;cmath&gt; void abssort(float *x, unsigned N)&#123; std::sort(x, x + N, [](float a, float b) &#123; return std::abs(a) &lt; std::abs(b); &#125;);&#125; 其中需要注意： 返回值类型-&gt;return-type可以省略，由语言自动推导，但前提是只有当 lambda 表达式中的语句“足够简单”，才能自动推断返回值类型。 引入 lambda 表达式的前导符是一对方括号，称为 lambda 引入符（lambda-introducer）。lambda 表达式可以使用与其相同范围 scope 内的变量。这个引入符的作用就是表明，其后的 lambda 表达式以何种方式使用（正式的术语是“捕获”）这些变量（这些变量能够在 lambda 表达式中被捕获，其实就是构成了一个闭包）。 捕获类型可以以下类型： [] // 不捕获任何外部变量 [=] // 以值的形式捕获所有外部变量 [&amp;] // 以引用形式捕获所有外部变量 [x, &amp;y] // x 以传值形式捕获，y 以引用形式捕获 [=, &amp;z]// z 以引用形式捕获，其余变量以传值形式捕获 [&amp;, x] // x 以值的形式捕获，其余变量以引用形式捕获 对于[=]或[&amp;]的形式，lambda 表达式可以直接使用 this 指针 。但是，对于[]的形式，如果要使用 this 指针，必须显式传入： 对于下面的例子，[=]意味着，lambda 表达式以传值的形式捕获外部变量。C++ 11 标准说，如果以传值的形式捕获外部变量，那么，lambda 体不允许修改外部变量，对 f0 的任何修改都会引发编译错误。但是，注意在 lambda 表达式前声明了mutable关键字，这就允许了 lambda 表达式体修改 f0 的值。因此不会报错。但由于是传值的，虽然在 lambda 表达式中对 f0 有了修改，但由于是传值的，外部的 f0 依然不会被修改。 123float f0 = 1.0;std::cout &lt;&lt; [=](float f) mutable &#123; return f0 += std::abs(f); &#125; (-3.5);std::cout &lt;&lt; '\n' &lt;&lt; f0 &lt;&lt; '\n'; – 混合机制的实例如下（f0 通过引用被捕获，而其它变量，比如 f1 则是通过值被捕获）： 1234float f0 = 1.0f;float f1 = 10.0f;std::cout &lt;&lt; [=, &amp;f0](float a) &#123; return f0 += f1 + std::abs(a); &#125; (-3.5);std::cout &lt;&lt; '\n' &lt;&lt; f0 &lt;&lt; '\n'; C++引入Lambda的最主要原因:1）可以定义匿名函数；2）编译器会把其转成函数对象；为什么以前STL中的ptr_fun()这个函数对象不能用？（ptr_fun()就是把一个自然函数转成函数对象的）原因是，ptr_fun() 的局限是其接收的自然函数只能有1或2个参数。3）”闭包”，限制了别人的访问，更私有； 2.自动类型推导和 decltype在 C++03 中，声明对象的同时必须指明其类型，其实大多数情况下，声明对象的同时也会包括一个初始值，C++11 在这种情况下就能够让你声明对象时不再指定类型了。 1234auto x = 0; //0 是 int 类型，所以 x 也是 int 类型 auto c = 'a'; //char auto d = 0.5; //double auto national_debt = 14400000000000LL;//long long 这个特性在对象的类型很大很长的时候很有用，如： 123456 void func(const vector&lt;int&gt; &amp;vi) &#123; //vector&lt;int&gt;::const_iterator ci=vi.begin(); auto ci=vi.begin(); &#125; C++11 也提供了从对象或表达式中“俘获”类型的机制，新的操作符 decltype 可以从一个表达式中“俘获”其结果的类型并“返回”： 123const vector&lt;int&gt; vi; typedef decltype (vi.begin()) CIT; CIT another_const_iterator; 注意： auto作为函数返回值时，只能用于定义函数，不能用于声明函数 3.统一的初始化语法12345678910111213141516//括号内初始化std::string s("hello"); int m=int(); //default initialization //等号形式的std::string s="hello"; int x=5; //对于 POD 集合，又可以用大括号int arr[4]=&#123;0,1,2,3&#125;; struct tm today=&#123;0&#125;; //最后还有构造函数的成员初始化：struct S &#123; int x; S(): x(0) &#123;&#125; &#125;; C++11 就用大括号一统天下了!对于容器来说，终于可以摆脱 push_back() 调用了，C++11中可以直观地初始化容器了: 12345// C++11 container initializer vector vs&lt;string&gt;=&#123; "first", "second", "third"&#125;; map singers = &#123; &#123;"Lady Gaga", "+1 (212) 555-7890"&#125;, &#123;"Beyonce Knowles", "+1 (212) 555-0987"&#125;&#125;; 而类中的数据成员初始化也得到了支持： 123456class C &#123; int a=7; //C++11 only public: C(); &#125;; 4.deleted 函数和 defaulted 函数12345struct A &#123; A()=default; //C++11 virtual ~A()=default; //C++11 &#125;; =default; 指示编译器生成该函数的默认实现。这有两个好处：一是让程序员轻松了，少敲键盘，二是有更好的性能。与 defaulted 函数相对的就是 deleted 函数, 实现 non copy-able 防止对象拷贝，要想禁止拷贝，用 =deleted 声明一下两个关键的成员函数就可以了： 12345678910int func()=delete; //防止对象拷贝的实现struct NoCopy &#123; NoCopy &amp; operator =(const NoCopy &amp;) = delete; NoCopy(const NoCopy &amp;) = delete; &#125;; NoCopy a; NoCopy b(a); //编译错误，拷贝构造函数是 deleted 函数 5.nullptrnullptr 是一个新的 C++ 关键字，它是空指针常量，它是用来替代高风险的 NULL 宏和 0 字面量的。nullptr 是强类型的,所有跟指针有关的地方都可以用 nullptr，包括函数指针和成员指针： 123456789101112void f(int); //#1 void f(char *);//#2 //C++03 f(0); //调用的是哪个 f? //C++11 f(nullptr) //毫无疑问，调用的是 #2 const char *pc=str.c_str(); //data pointers if (pc != nullptr) cout &lt;&lt; pc &lt;&lt; endl; int (A::*pmf)()=nullptr; //指向成员函数的指针 void (*pmf)()=nullptr; //指向函数的指针 6.右值引用在 C++03 中的引用类型是只绑定左值的，C++11 引用一个新的引用类型叫右值引用类型，它是绑定到右值的，如临时对象或字面量。增加右值引用的主要原因是为了实现 move 语义。与传统的拷贝不同，move 的意思是目标对象“窃取”原对象的资源，并将源置于“空”状态。当拷贝一个对象时，其实代价昂贵且无必要，move 操作就可以替代它。如在 string 交换的时候，使用 move 意义就有巨大的性能提升，如下所示： 12345678910111213141516171819202122//原方案很慢，因为需要申请内存，然后拷贝字符；[cpp] view plain copyvoid naiveswap(string &amp;a, string &amp; b) &#123; string temp = a; a=b; b=temp; &#125; //使用move就只需要交换两个数据成员，无须申请、释放内存和拷贝字符数组；void moveswapstr(string&amp; empty, string &amp; filled) &#123; //pseudo code, but you get the idea size_t sz=empty.size(); const char *p= empty.data(); //move filled's resources to empty empty.setsize(filled.size()); empty.setdata(filled.data()); //filled becomes empty filled.setsize(sz); filled.setdata(p); &#125; 要实现支持 move 的类，需要声明 move 构造函数和 move 赋值操作符，如下： 12345class Movable &#123; Movable (Movable&amp;&amp;); //move constructor Movable&amp;&amp; operator=(Movable&amp;&amp;); //move assignment operator &#125;; C++11 的标准库线程库、新的智能指针类、]]></content>
      <tags>
        <tag>技术 编程语言 C++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker常用命令]]></title>
    <url>%2F2018%2F12%2F27%2Fdocker%2F</url>
    <content type="text"><![CDATA[docker是什么？docker是一个开源的容器引擎，它基于LCX容器技术，使用Go语言开发。源代码托管在Github上，并遵从Apache2.0协议。Docker采用C/S架构，其可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。 简单来说：Docker就是一种快速解决生产问题的一种技术手段。简单点：Docker就是对容器进行操作管理的工具 docker优缺点优点：多： 适用场景多快： 环境部署快、更新快好： 好多人在用省： 省钱省力省人工 缺点：太腻歪人： 依赖操作系统不善沟通： 依赖网络不善理财： 银行U盾等场景不能用 镜像命令搜索 ： docker search 【image_name】获取 ： docker pull 【image_name】查看 ： docker image 【image_name】docker image -a 列出本地的image（包括已删除的镜像记录）镜像重命名： docker tag [old_name]:[old_version] [new_name]:[new_verdion]删除镜像：docker rmi [image_id]导出镜像：（将已下载好的镜像，导出到本地） docker save -o [导出镜像名称] [本地镜像] 例：docker save -o nginx.tar nginx 导入镜像： docker load &lt; [image.tar_name] 容器命令查看容器： docker ps启动容器三种方式： 基于镜像新建一个容器并启动docker run &lt;参数，可选&gt; [docker_image] [执行命令]docker run 其实是两个命令的结合体docker create + docker start 将关闭的容器重新启动docker start [container_id] 守护进程方式启动(常用方式)docker run -d [image_name] command…例：docker run -d nginx 关闭容器： docker stop [container_id] 删除容器的三种方式：1.正常删除- - -删除已关闭的docker rm [container_id] 2.强制删除- - - 删除正在运行的docker rm -f [container_id] 3.强制批量删除- - - 删除全部容器docker rm -f $(docker ps -a -q) 进入容器三种方法：1.创建容器的同事并且进入容器docker run –name [container_name] -it [docker_image] /bin/bash 2.手工方式进入容器docker exec -it 容器id /bin/bash 3.生产方式进入容器 我们生产中常用的进入容器方法是使用脚本，脚本内容如下: 12345678#!/bin/bash# 定义进入仓库函数docker_in()&#123; NAME_ID=$1 PID=$(docker inspect --format &#123;&#123;.State.Pid&#125;&#125; $NAME_ID) nsenter --target $PID --mount --uts --ipc --net --pid&#125;docker_in $1]]></content>
      <tags>
        <tag>技术 容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO阻塞与非阻塞一篇就够了]]></title>
    <url>%2F2018%2F12%2F27%2Fio_sync%2F</url>
    <content type="text"><![CDATA[什么叫IOio通常是指计算机系统输入和输出的称呼，包括设备（键盘鼠标显示器）、总线、磁盘读写、内存等都称之为IO。 IO阻塞与非阻塞阻塞（block）：用户态进程切换至内核态进程（read，write，accept等API函数系统调用），用户态进程一直处于挂起状态，直至内核态返回，继续工作。 非阻塞（nonblock）:用户态进程切换至内核态进程（read，write，accept等API函数系统调用），内核态进程会立马返回数据或状态码给用户态进程，用户态进程无需处于挂起状态，一直处于忙碌状态。 同步与异步同步（synchronous）:一个服务进行数据请求时，服务方立马告知请求结果，若数据不满足，请求方会再次主动发送请求到服务方，直至请求方得到满意的回复。（期望的结果） 异步（asynchronous）：客户向服务方请求，服务方也会立马回复请求方，不同的是，客户请求方只留下一个回调函数，用来让服务方等待条件满足后，主动通知客户方最终结果。（此方式客户方只请求了一次服务方） 阻塞、非阻塞和同步异步是两个不同的概念。 同步与异步最大的差异是对待结果的返回方式不一样。]]></content>
      <tags>
        <tag>技术 linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2018%2F12%2F26%2Fthreadpool%2F</url>
    <content type="text"><![CDATA[为什么需要线程池在那些情况下我们会使用到多线程： 1.阻塞调用（阻塞IO调用、等待资源）2.耗时的计算（读写文件、复杂的计算）3.高密度任务（高并发低延时的网络IO请求）面临以上情况时都去临时创建线程会带来什么问题： 1.创建了太多的线程，系统资源就会被浪费，而且会浪费时间去创建和销毁线程。2.创建线程太慢，导致执行任务结果返回过慢。3.销毁线程太慢，可能会影响别的进程使用资源。所以：创建多个线程，放在池子里不销毁，要用的时候就把任务丢给池子里的线程去执行，这就是线程池。OK，问题来了任务由谁产生（生产者），如何丢给线程池的某个线程（消费者）？这个问题的回答需从以下几方面： 1） 生产者采用什么方式与消费者同步？2） 任务如何保存？3） 生产者之间的同步方式，消费者之间的同步方式？ 一下所有的代码设计适用于单生产者多消费者模式 条件变量结合互斥锁 + 任务队列设计如何： 代码如下： 123456789101112131415161718192021222324252627typedef struct queue_task&#123; void* (*run)(void *); void* argv;&#125;task_t;typedef struct queue&#123; int head; int tail; int size; int capcity; task_t* tasks;&#125; queue_t;typedef struct async_queue&#123; pthread_mutex_t mutex; pthread_cond_t cond; int waiting_threads; queue_t* queue; int quit; // 0 表示不退出 1 表示退出 /* 调试变量 */ long long tasked; // 已经处理完的任务数量&#125; async_queue_t; 取任务的代码设计如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344task_t* async_cond_queue_pop_head(async_queue_t* q, int timeout)&#123; task_t *task = NULL; struct timeval now; struct timespec outtime; pthread_mutex_lock(&amp;(q-&gt;mutex)); if (queue_is_empty(q-&gt;queue)) &#123; q-&gt;waiting_threads++; while (queue_is_empty(q-&gt;queue) &amp;&amp; (q-&gt;quit == 0)) &#123; gettimeofday(&amp;now, NULL); if (now.tv_usec + timeout &gt; 1000) &#123; outtime.tv_sec = now.tv_sec + 1; outtime.tv_nsec = ((now.tv_usec + timeout) % 1000) * 1000; &#125; else &#123; outtime.tv_sec = now.tv_sec; outtime.tv_nsec = (now.tv_usec + timeout) * 1000; &#125; pthread_cond_timedwait(&amp;(q-&gt;cond), &amp;(q-&gt;mutex), &amp;outtime); &#125; q-&gt;waiting_threads--; &#125; task = queue_pop_head(q-&gt;queue); /* 调试代码 */ if (task) &#123; q-&gt;tasked ++; static long long precision = 10; if ((q-&gt;tasked % precision ) == 0) &#123; time_t current_stm = get_current_timestamp(); precision *= 10; &#125; &#125; pthread_mutex_unlock(&amp;(q-&gt;mutex)); return task;&#125; 详情见：https://github.com/zhiyong0804/f-threadpool/blob/master/async_cond_queue.c 不足： 因为Mutex引起线程挂起和唤醒的操作，在IO密集型的服务器上不是特别高效（实测过）；条件变量必须和互斥锁相结合使用，使用起来较麻烦；条件变量不能像eventfd一样为I/O事件驱动。管道可以和I/O复用很好的融合，但是管道比eventfd多用了一个文件描述符，而且管道内核还得给其管理的缓冲区，eventfd则不需要，因此eventfd比起管道要高效。 eventfd + epoll队列的设计： 1234567891011typedef struct async_queue&#123; queue_t* queue; int quit; // 0 表示不退出 1 表示退出 int efd; //event fd, int epollfd; // epoll fd /* 调试变量 */ long long tasked; // 已经处理完的任务数量&#125; async_queue_t; 插入任务： 123456789101112131415161718192021222324BOOL async_eventfd_queue_push_tail(async_queue_t* q, task_t *task)&#123; unsigned long long i = 0xffffffff; if (!queue_is_full(q-&gt;queue)) &#123; queue_push_tail(q-&gt;queue, task); struct epoll_event ev; int efd = eventfd(0, EFD_CLOEXEC | EFD_NONBLOCK); if (efd == -1) printf("eventfd create: %s", strerror(errno)); ev.events = EPOLLIN ;// | EPOLLLT; ev.data.fd = efd; if (epoll_ctl(q-&gt;epollfd, EPOLL_CTL_ADD, efd, &amp;ev) == -1) &#123; return NULL; &#125; write(efd, &amp;i, sizeof (i)); return TRUE; &#125; return FALSE;&#125; 取任务： 1234567891011121314151617181920212223242526272829303132task_t* async_eventfd_queue_pop_head(async_queue_t* q, int timeout)&#123; unsigned long long i = 0; struct epoll_event events[MAX_EVENTS]; int nfds = epoll_wait(q-&gt;epollfd, events, MAX_EVENTS, -1); if (nfds == -1) &#123; return NULL; &#125; else &#123; read(events[0].data.fd, &amp;i, sizeof (i)); close(events[0].data.fd); // NOTE: need to close here task_t* task = queue_pop_head(q-&gt;queue); /* 调试代码 */ if (task) &#123; q-&gt;tasked ++; static long long precision = 10; if ((q-&gt;tasked % precision ) == 0) &#123; time_t current_stm = get_current_timestamp(); printf("%d tasks cost : %d\n", precision, current_stm - start_stm); precision *= 10; &#125; &#125; return task; &#125; return NULL;&#125; 因为eventfd每次写数据后，只会唤醒一个epoll_wait所在的线程，so，确保了同一时刻仅有一个线程取任务。代码详情：https://github.com/zhiyong0804/f-threadpool/blob/master/async_eventfd_queue.c 不足：上面两种方案，所有的线程共用同一个队列，所以消费者线程之间取任务时需要做同步，生产者和消费者也需要做同步。用一个形象的图可以表示如下： eventfd + epoll + 多队列的设计设计思想如下图： 代码详情见：https://github.com/zhiyong0804/StreamingServerOh my god, huge project, where can i find thre thread pool source. 说来话长，这个代码是EasyDarwin的源码，但是因为某种原因，EasyDarwin的源码不再共享，取而代之的打赏的二维码，so， 我把他们的源码做了局部的修改，然后重新提交，且命名为StreamingServer，里面的设计是采用条件变量做同步的，但是多队列的思想是可以沿袭的，打算加班用eventfd实现。 这样一种设计是不是让我们能够想到下面这幅图呢？ 之前所有的道路遇到十字路口时（共享了资源），只能使用信号灯去同步汽车的行驶，现如今，把共享资源fuck掉了，用立交桥，爽吧！！！？ 并行编程是很难的，可以参考以下这篇论文: 并发编程的11个问题英文版：http://www.it610.com/article/4462577.htm并发编程的11个问题中文版：https://blog.csdn.net/mergerly/article/details/39028861我也并不聪明，可是当我2年前接触到ZeroMQ这个项目时，我特别惊叹于Pieter Hintjens的一些观点，“真正的并发就是不共享资源” so，方案四的设计 Lock-free当我们在第三种方案上，增加了多队列，即每线程每队列时，实际上我们的队列设计变成了一个单生产者单消费者共享的队列，但是这个队列的写指针（tail）仅会被生产者使用，读指针（head）仅会被消费者使用，实际上没有共享任何资源，当然queue_t的size变量，我正在重构把它拿掉。 OK，那么在这种设计下，消费者线程如何“等待”如何“取”任务？ 实际上，上面的三种方案对于消费者线程都是被动等待通知，收到通知则去取任务，实际上，我们完全可以设计成“轮询”的方案，就是不停地看自己的任务队列里是否有任务，没有就循环一次，中间当然可以加上sched_yield操作，让其它的线程能够得到调度。 线程池的尺寸设计多大合适？CPU密集型的：thread size = N + 1;IO密集型的：thread size = 2*N + 1; 当然这不是绝对的，所以在mariadb的线程池是可以动态调整这个尺寸的。 ——————————————全文完—————————————————–]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mutex的实现原理]]></title>
    <url>%2F2018%2F12%2F26%2Fmutex%2F</url>
    <content type="text"><![CDATA[互斥锁主要用于实现内核中的互斥访问功能。内核互斥锁是在原子 API 之上实现的，但这对于内核用户是不可见的。对它的访问必须遵循一些规则：同一时间只能有一个任务持有互斥锁，而且只有这个任务可以对互斥锁进行解锁。互斥锁不能进行递归锁定或解锁。一个互斥锁对象必须通过其API初始化，而不能使用memset或复制初始化。一个任务在持有互斥锁的时候是不能结束的。互斥锁所使用的内存区域是不能被释放的。使用中的互斥锁是不能被重新初始化的。并且互斥锁不能用于中断上下文。但是互斥锁比当前的内核信号量选项更快，并且更加紧凑，因此如果它们满足您的需求，那么它们将是您明智的选择。 定义123456789101112131415164.15 kernelinclude/linux/mutex.hstruct mutex &#123; atomic_long_t owner; spinlock_t wait_lock;#ifdef CONFIG_MUTEX_SPIN_ON_OWNER struct optimistic_spin_queue osq; /* Spinner MCS lock */#endif struct list_head wait_list;#ifdef CONFIG_DEBUG_MUTEXES void *magic;#endif#ifdef CONFIG_DEBUG_LOCK_ALLOC struct lockdep_map dep_map;#endif&#125;; 1.owner锁的持有者, 如果没有task持有则为0，否则是获取到锁的pid。2.wait_lock自旋锁，内核用来保护代码执行区的。3.wait_list等待队列，是一个链表，如果task没有获取owner == 0，则把task加入到这个等待队列，并且将进程设置为TASK_UNINTERRUPTIBLE状态，直到被wakeup调用唤醒执行。 mutex_lock123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213// linux/kener/locking/mutex.c:252/** * mutex_lock - acquire the mutex * @lock: the mutex to be acquired * * Lock the mutex exclusively for this task. If the mutex is not * available right now, it will sleep until it can get it. * * The mutex must later on be released by the same task that * acquired it. Recursive locking is not allowed. The task * may not exit without first unlocking the mutex. Also, kernel * memory where the mutex resides must not be freed with * the mutex still locked. The mutex must first be initialized * (or statically defined) before it can be locked. memset()-ing * the mutex to 0 is not allowed. * * (The CONFIG_DEBUG_MUTEXES .config option turns on debugging * checks that will enforce the restrictions and will also do * deadlock debugging) * * This function is similar to (but not equivalent to) down(). */void __sched mutex_lock(struct mutex *lock)&#123; might_sleep(); if (!__mutex_trylock_fast(lock)) __mutex_lock_slowpath(lock);&#125;static __always_inline bool __mutex_trylock_fast(struct mutex *lock)&#123; unsigned long curr = (unsigned long)current; unsigned long zero = 0UL; if (atomic_long_try_cmpxchg_acquire(&amp;lock-&gt;owner, &amp;zero, curr)) return true; return false;&#125;/* * Lock a mutex (possibly interruptible), slowpath: */static __always_inline int __sched__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass, struct lockdep_map *nest_lock, unsigned long ip, struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)&#123; struct mutex_waiter waiter; bool first = false; struct ww_mutex *ww; int ret; might_sleep(); ww = container_of(lock, struct ww_mutex, base); if (use_ww_ctx &amp;&amp; ww_ctx) &#123; if (unlikely(ww_ctx == READ_ONCE(ww-&gt;ctx))) return -EALREADY; /* * Reset the wounded flag after a kill. No other process can * race and wound us here since they can't have a valid owner * pointer if we don't have any locks held. */ if (ww_ctx-&gt;acquired == 0) ww_ctx-&gt;wounded = 0; &#125; preempt_disable(); mutex_acquire_nest(&amp;lock-&gt;dep_map, subclass, 0, nest_lock, ip); if (__mutex_trylock(lock) || mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) &#123; /* got the lock, yay! */ lock_acquired(&amp;lock-&gt;dep_map, ip); if (use_ww_ctx &amp;&amp; ww_ctx) ww_mutex_set_context_fastpath(ww, ww_ctx); preempt_enable(); return 0; &#125; spin_lock(&amp;lock-&gt;wait_lock); /* * After waiting to acquire the wait_lock, try again. */ if (__mutex_trylock(lock)) &#123; if (use_ww_ctx &amp;&amp; ww_ctx) __ww_mutex_check_waiters(lock, ww_ctx); goto skip_wait; &#125; debug_mutex_lock_common(lock, &amp;waiter); lock_contended(&amp;lock-&gt;dep_map, ip); if (!use_ww_ctx) &#123; /* add waiting tasks to the end of the waitqueue (FIFO): */ __mutex_add_waiter(lock, &amp;waiter, &amp;lock-&gt;wait_list);#ifdef CONFIG_DEBUG_MUTEXES waiter.ww_ctx = MUTEX_POISON_WW_CTX;#endif &#125; else &#123; /* * Add in stamp order, waking up waiters that must kill * themselves. */ ret = __ww_mutex_add_waiter(&amp;waiter, lock, ww_ctx); if (ret) goto err_early_kill; waiter.ww_ctx = ww_ctx; &#125; waiter.task = current; set_current_state(state); for (;;) &#123; /* * Once we hold wait_lock, we're serialized against * mutex_unlock() handing the lock off to us, do a trylock * before testing the error conditions to make sure we pick up * the handoff. */ if (__mutex_trylock(lock)) goto acquired; /* * Check for signals and kill conditions while holding * wait_lock. This ensures the lock cancellation is ordered * against mutex_unlock() and wake-ups do not go missing. */ if (unlikely(signal_pending_state(state, current))) &#123; ret = -EINTR; goto err; &#125; if (use_ww_ctx &amp;&amp; ww_ctx) &#123; ret = __ww_mutex_check_kill(lock, &amp;waiter, ww_ctx); if (ret) goto err; &#125; spin_unlock(&amp;lock-&gt;wait_lock); schedule_preempt_disabled(); /* * ww_mutex needs to always recheck its position since its waiter * list is not FIFO ordered. */ if ((use_ww_ctx &amp;&amp; ww_ctx) || !first) &#123; first = __mutex_waiter_is_first(lock, &amp;waiter); if (first) __mutex_set_flag(lock, MUTEX_FLAG_HANDOFF); &#125; set_current_state(state); /* * Here we order against unlock; we must either see it change * state back to RUNNING and fall through the next schedule(), * or we must see its unlock and acquire. */ if (__mutex_trylock(lock) || (first &amp;&amp; mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &amp;waiter))) break; spin_lock(&amp;lock-&gt;wait_lock); &#125; spin_lock(&amp;lock-&gt;wait_lock);acquired: __set_current_state(TASK_RUNNING); if (use_ww_ctx &amp;&amp; ww_ctx) &#123; /* * Wound-Wait; we stole the lock (!first_waiter), check the * waiters as anyone might want to wound us. */ if (!ww_ctx-&gt;is_wait_die &amp;&amp; !__mutex_waiter_is_first(lock, &amp;waiter)) __ww_mutex_check_waiters(lock, ww_ctx); &#125; mutex_remove_waiter(lock, &amp;waiter, current); if (likely(list_empty(&amp;lock-&gt;wait_list))) __mutex_clear_flag(lock, MUTEX_FLAGS); debug_mutex_free_waiter(&amp;waiter);skip_wait: /* got the lock - cleanup and rejoice! */ lock_acquired(&amp;lock-&gt;dep_map, ip); if (use_ww_ctx &amp;&amp; ww_ctx) ww_mutex_lock_acquired(ww, ww_ctx); spin_unlock(&amp;lock-&gt;wait_lock); preempt_enable(); return 0;err: __set_current_state(TASK_RUNNING); mutex_remove_waiter(lock, &amp;waiter, current);err_early_kill: spin_unlock(&amp;lock-&gt;wait_lock); debug_mutex_free_waiter(&amp;waiter); mutex_release(&amp;lock-&gt;dep_map, 1, ip); preempt_enable(); return ret;&#125; 从以上代码可以看出，如果task获取不到锁，则先把自己加入到等待队列，并且设置进程状态为TASK_UNINTERRUPTIBLE，让出CPU的执行。 mutex_unlock1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * mutex_unlock - release the mutex * @lock: the mutex to be released * * Unlock a mutex that has been locked by this task previously. * * This function must not be used in interrupt context. Unlocking * of a not locked mutex is not allowed. * * This function is similar to (but not equivalent to) up(). */void __sched mutex_unlock(struct mutex *lock)&#123;#ifndef CONFIG_DEBUG_LOCK_ALLOC if (__mutex_unlock_fast(lock)) return;#endif __mutex_unlock_slowpath(lock, _RET_IP_);&#125;/* * Release the lock, slowpath: */static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)&#123; struct task_struct *next = NULL; DEFINE_WAKE_Q(wake_q); unsigned long owner; mutex_release(&amp;lock-&gt;dep_map, 1, ip); /* * Release the lock before (potentially) taking the spinlock such that * other contenders can get on with things ASAP. * * Except when HANDOFF, in that case we must not clear the owner field, * but instead set it to the top waiter. */ owner = atomic_long_read(&amp;lock-&gt;owner); for (;;) &#123; unsigned long old;#ifdef CONFIG_DEBUG_MUTEXES DEBUG_LOCKS_WARN_ON(__owner_task(owner) != current); DEBUG_LOCKS_WARN_ON(owner &amp; MUTEX_FLAG_PICKUP);#endif if (owner &amp; MUTEX_FLAG_HANDOFF) break; old = atomic_long_cmpxchg_release(&amp;lock-&gt;owner, owner, __owner_flags(owner)); if (old == owner) &#123; if (owner &amp; MUTEX_FLAG_WAITERS) break; return; &#125; owner = old; &#125; spin_lock(&amp;lock-&gt;wait_lock); debug_mutex_unlock(lock); if (!list_empty(&amp;lock-&gt;wait_list)) &#123; /* get the first entry from the wait-list: */ struct mutex_waiter *waiter = list_first_entry(&amp;lock-&gt;wait_list, struct mutex_waiter, list); next = waiter-&gt;task; debug_mutex_wake_waiter(lock, waiter); wake_q_add(&amp;wake_q, next); &#125; if (owner &amp; MUTEX_FLAG_HANDOFF) __mutex_handoff(lock, next); spin_unlock(&amp;lock-&gt;wait_lock); wake_up_q(&amp;wake_q);&#125; 释放锁时，先检查ower是否是自己，如果是的，则从等待队列（wait_list）拿取第一个task，并且调用wake_up_q去唤醒task，task恢复执行。 ——————————————全文完—————————————————–]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协程]]></title>
    <url>%2F2018%2F12%2F26%2Fxiecheng%2F</url>
    <content type="text"><![CDATA[协程，英文（coroutines）,是一种比线程更加轻量级的存在。 一个进程可以拥有多个线程，一个线程也可以拥有多个协程。 最重要的是，协程不是被操作系统内核所管理（内核调用），而完全是由用户态程序所控制（用户态执行）。 这样带来的好处就是性能得到了很大的提升，不像进程线程切换带来的消耗资源，cpu的调度。 协程的开销远远小于线程的开销。 协程并不想线程需要锁机制，协程中控制共享资源不加锁，只需要判断状态就好，所以执行效率比多线程高的多。 因为协程是一个线程执行，那怎么利用多核CPU呢？ 最简单的方法就是多进程+协程，既充分利用多核，又充分发挥协程的高效率。 ==协程允许我们写同步代码的逻辑，却做着异步的事，避免回调嵌套，使得代码逻辑清晰（协程是追求极限性能和优美的代码结构产物）== 参考手册 : 协程详细介绍]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <url>%2F2018%2F12%2F26%2Fgit%2F</url>
    <content type="text"><![CDATA[1.git与SVN的区别git是分布式版本控制系统。必须客户端连接上服务端才能正常工作。svn是集中式版本控制系统。每台机器就是一个单独运行的库，方便高效便捷的开发。 2.git常用命令git config -global ; 配置环境信息git init ；将目录变成git管理的仓库，初始化仓库git add ;提交到暂存区git commit; 提交到本地仓git status ;查看仓库是否有文件未提交git diff 文件名；比较文件git reset -hard HEAD~100;回到前100个版本git reset -hard(版本号)；回到指定的版本号git reflog；取得版本号 git checkout -b ;创建并且换到分支git branch dev ；创建分支git checkout dev；切换分支git merge dev; 将dev分支上的内容合并到主支master上git branch -d name;删除分支 参考手册 : git详细介绍]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua脚本式编程]]></title>
    <url>%2F2018%2F12%2F26%2Flua%2F</url>
    <content type="text"><![CDATA[1.基本语法单行注释：–多行注释：–[[ 内容–]] lua最好不要使用下划线加大字母的标识符，因为lua的保留字是这样的。lua不允许使用特殊字符如@$%来定义标志符。 默认情况下，变量总是认为全局。删除全局变量，只需要将变量赋值nil . lua的数据类型：nil 、boolean、number、string、userdata、function、thread和table。 nil作为比较时应该加上双引号，例如 12type(x) == &quot;nil&quot; boolean类型只有两个可选值：true 和 falselua把false和nil看作是“假”，其他都为真。 number（数字）：lua只有一种number类型，double双精度类型，默认类型可以修改luaconf.h里面的定义。 string（字符串）：由一对双引号或单引号来表示，也可以用2个方括号“[[ ]]”来表示“一块”字符串。 对一个数字字符串上进行算术操作时，lua会尝试将这个数字字符串转换成一个数字。 12print(“2”+6) 8.0print("2"+"6") 8.0 字符串连接使用的是 . .如： 12print("a" .. "b") abprint(157 .. 428) 157428 #计算字符串的长度。 123len ="www.runoob.com"print(#len) 14print(#"www.runoob.com") 14 2.宿主语言C/C++==虚拟栈== 无论何时lua调用C，被调用的函数都得到一个新的栈，这个栈独立于C函数本身的栈，也独立于之前的栈。 方便起见，所有正对栈的API查询操作都不严格遵守栈的操作规则。而是可以用一个索引来指向栈上的任何元素： ==正的索引指的是栈上的绝对位置（从1开始），负的索引指从栈顶开始的偏移量。== Lua_checkstack:扩大可用堆栈的尺寸LUA_MINSTACK一般被定义为20。 压入栈的数据类型包括数值、字符串、指针、table、闭包。 Lua_pushcclosure(L,func,0)；创建并压入一个闭包Lua_createtable(L,0,0)；新建并压入一个表Lua_pushnumber(L,343)；压入一个数字Lua_pushstring(L,”Nystr”)；压入一个字符串 Lua中，number、boolean、nil、lightuserdata四种类型的值是直接存在栈上元素里和垃圾回收无关。Lua中，string、table、closure、userdata、thread存在栈上元素里的只是指针，他们都会在生命周期结束后被垃圾回收。 Lua_push族函数都有“创建一个类型的值并压入”的语义。Lua value -&gt; C value时，是通过Lua_to族api实现的。 123456取表中元素 void lua_getfield(lua_state *L,int index,const char *K)操作： arr = stack[index] stack.push(arr[K]) 取表中键为K的元素，这里的表是由index指向的栈上的一个表。 栈高度+1，栈顶元素是（stack[index]）[K]。]]></content>
      <tags>
        <tag>技术,编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP通讯知识]]></title>
    <url>%2F2018%2F11%2F25%2FTCP-IP%E9%80%9A%E8%AE%AF%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"></content>
      <categories>
        <category>TCP</category>
      </categories>
      <tags>
        <tag>TCP网络通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test_md]]></title>
    <url>%2F2018%2F11%2F23%2Ftest-md%2F</url>
    <content type="text"></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F11%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[notshow: trueWelcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hexo查询</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
